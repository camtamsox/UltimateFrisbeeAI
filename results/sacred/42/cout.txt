{'exp_name': 'default', 'display': False, 'restore_fp': None, 'save_rate': 10, 'scenario_name': 'ultimate_frisbee', 'num_episodes': 6000, 'max_episode_len': 10000, 'good_policy': 'matd3', 'adv_policy': 'matd3', 'lr': 0.01, 'gamma': 0.95, 'batch_size': 1024, 'num_layers': 2, 'num_units': 64, 'update_rate': 100, 'critic_zero_if_done': False, 'buff_size': 100000.0, 'tau': 0.01, 'hard_max': False, 'priori_replay': False, 'alpha': 0.6, 'beta': 0.5, 'use_target_action': True, 'policy_update_rate': 1, 'critic_action_noise_stddev': 0.0, 'action_noise_clip': 0.5, 'entropy_coeff': 0.05, 'num_atoms': 51, 'min_val': -400, 'max_val': 0, 'seed': 502604963}
C:\Users\camta\miniconda3\lib\site-packages\keras\optimizers\optimizer_v2\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
Using good policy matd3 and adv policy matd3
42
Starting iterations...
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
steps: 10074, episodes: 10, mean episode reward: -19391.666666666668, agent episode reward: [-7553.666666666667, -7553.111111111111, -7547.555555555556, -7531.444444444444, -7562.0, -7557.555555555556, -7553.111111111111, 4412.0, 4458.666666666667, 6889.777777777777, 4412.0, 4440.888888888889, 4431.444444444444, 4422.0], time: 115.04
steps: 10161, episodes: 20, mean episode reward: 62847.77777777778, agent episode reward: [-1008.0, -1008.0, -1008.0, -1008.0, -1010.7777777777778, -1008.5555555555555, -1008.0, 9968.0, 10006.888888888889, 10008.0, 9968.0, 9994.666666666666, 9984.666666666666, 9976.888888888889], time: 1.652
steps: 40189, episodes: 30, mean episode reward: -183152.77777777778, agent episode reward: [-20639.555555555555, -20644.0, -20621.222222222223, -20581.222222222223, -20649.555555555555, -20646.222222222223, -20635.666666666668, -6678.222222222223, -6639.888888888889, 1245.6666666666667, -6678.222222222223, -6652.666666666667, -6662.666666666667, -6669.333333333333], time: 343.498
steps: 60263, episodes: 40, mean episode reward: -101252.77777777778, agent episode reward: [-14097.333333333334, -14097.888888888889, -14085.111111111111, -14057.888888888889, -14105.666666666666, -14102.333333333334, -14092.888888888889, -1136.0, -1089.888888888889, 4094.5555555555557, -1134.888888888889, -1105.4444444444443, -1116.0, -1126.0], time: 222.79
game has been saved from episode: 50
steps: 60377, episodes: 50, mean episode reward: 62741.11111111111, agent episode reward: [-1012.4444444444445, -1013.0, -1011.8888888888889, -1011.8888888888889, -1020.7777777777778, -1017.4444444444445, -1011.8888888888889, 9952.444444444445, 10006.888888888889, 10011.888888888889, 9952.444444444445, 9983.0, 9971.333333333334, 9962.444444444445], time: 2.233
steps: 70443, episodes: 60, mean episode reward: -19291.11111111111, agent episode reward: [-7551.222222222223, -7552.333333333333, -7545.111111111111, -7531.777777777777, -7554.555555555556, -7553.444444444444, -7551.777777777777, 4421.777777777777, 4457.333333333333, 6929.555555555556, 4421.777777777777, 4447.333333333333, 4439.555555555556, 4431.777777777777], time: 107.517
steps: 70484, episodes: 70, mean episode reward: 62944.444444444445, agent episode reward: [-1004.0, -1004.0, -1004.0, -1004.0, -1004.0, -1004.0, -1004.0, 9984.0, 10003.444444444445, 10004.0, 9984.555555555555, 10004.0, 9999.0, 9993.444444444445], time: 1.356
steps: 70600, episodes: 80, mean episode reward: 62735.555555555555, agent episode reward: [-1012.8888888888889, -1014.0, -1011.7777777777778, -1011.7777777777778, -1024.0, -1018.4444444444445, -1012.3333333333334, 9952.888888888889, 10005.111111111111, 10011.777777777777, 9952.888888888889, 9983.444444444445, 9971.777777777777, 9962.888888888889], time: 2.212
steps: 80638, episodes: 90, mean episode reward: -19186.11111111111, agent episode reward: [-7549.444444444444, -7548.333333333333, -7543.333333333333, -7528.333333333333, -7552.777777777777, -7551.666666666667, -7548.888888888889, 4428.888888888889, 4456.111111111111, 6988.888888888889, 4428.888888888889, 4450.0, 4445.555555555556, 4438.333333333333], time: 107.768
game has been saved from episode: 100
steps: 90727, episodes: 100, mean episode reward: -19396.666666666668, agent episode reward: [-7554.666666666667, -7556.333333333333, -7548.555555555556, -7533.555555555556, -7563.0, -7558.555555555556, -7543.555555555556, 4408.0, 4459.666666666667, 6901.333333333333, 4409.111111111111, 4439.666666666667, 4426.333333333333, 4417.444444444444], time: 107.78
steps: 100805, episodes: 110, mean episode reward: 62825.0, agent episode reward: [-1008.6666666666666, -1010.3333333333334, -1008.6666666666666, -1008.6666666666666, -1014.2222222222222, -1011.4444444444445, -1008.6666666666666, 9965.333333333334, 10005.888888888889, 10008.666666666666, 9965.888888888889, 9992.0, 9983.111111111111, 9974.777777777777], time: 107.911
steps: 110839, episodes: 120, mean episode reward: -19079.444444444445, agent episode reward: [-7549.222222222223, -7550.333333333333, -7543.111111111111, -7526.444444444444, -7552.555555555556, -7551.444444444444, -7548.666666666667, 4429.777777777777, 4455.888888888889, 7090.333333333333, 4429.777777777777, 4450.333333333333, 4447.0, 4439.222222222223], time: 107.813
steps: 120903, episodes: 130, mean episode reward: -19218.88888888889, agent episode reward: [-7551.555555555556, -7551.555555555556, -7545.444444444444, -7531.555555555556, -7559.333333333333, -7556.0, -7529.333333333333, 4420.444444444444, 4456.0, 6997.111111111111, 4421.555555555556, 4444.333333333333, 4436.555555555556, 4429.888888888889], time: 108.314
steps: 140986, episodes: 140, mean episode reward: -101503.33333333333, agent episode reward: [-14100.111111111111, -14100.666666666666, -14086.777777777777, -14058.444444444445, -14113.444444444445, -14109.0, -14084.555555555555, -1142.6666666666667, -1093.2222222222222, 3896.777777777778, -1142.6666666666667, -1112.111111111111, -1123.7777777777778, -1132.6666666666667], time: 213.461
game has been saved from episode: 150
steps: 151018, episodes: 150, mean episode reward: 62943.88888888889, agent episode reward: [-1003.5555555555555, -1003.5555555555555, -1003.5555555555555, -1003.5555555555555, -1004.6666666666666, -1003.5555555555555, -1003.5555555555555, 9985.777777777777, 10003.555555555555, 10003.555555555555, 9985.777777777777, 9999.666666666666, 9998.0, 9993.555555555555], time: 108.286
steps: 151103, episodes: 160, mean episode reward: 62842.22222222222, agent episode reward: [-1007.6666666666666, -1009.8888888888889, -1007.6666666666666, -1007.6666666666666, -1014.3333333333334, -1012.1111111111111, -1008.2222222222222, 9969.333333333334, 10004.333333333334, 10007.666666666666, 9969.888888888889, 9993.777777777777, 9986.555555555555, 9978.222222222223], time: 1.895
steps: 161171, episodes: 170, mean episode reward: -19497.777777777777, agent episode reward: [-7554.0, -7554.0, -7546.777777777777, -7532.888888888889, -7564.555555555556, -7560.111111111111, -7532.333333333333, 4415.111111111111, 4454.555555555556, 6765.666666666667, 4415.111111111111, 4439.0, 4432.888888888889, 4424.555555555556], time: 115.604
steps: 171249, episodes: 180, mean episode reward: -19503.88888888889, agent episode reward: [-7554.111111111111, -7555.222222222223, -7548.0, -7534.111111111111, -7565.222222222223, -7560.777777777777, -7553.0, 4410.222222222223, 4456.888888888889, 6807.444444444444, 4410.222222222223, 4436.333333333333, 4426.333333333333, 4419.111111111111], time: 114.464
steps: 171330, episodes: 190, mean episode reward: 62843.333333333336, agent episode reward: [-1007.8888888888889, -1010.1111111111111, -1007.3333333333334, -1007.3333333333334, -1014.5555555555555, -1012.3333333333334, -1007.8888888888889, 9970.666666666666, 10002.333333333334, 10007.333333333334, 9970.666666666666, 9994.0, 9986.222222222223, 9979.555555555555], time: 1.929
game has been saved from episode: 200
steps: 201373, episodes: 200, mean episode reward: -183224.44444444444, agent episode reward: [-20640.555555555555, -20640.555555555555, -20622.222222222223, -20576.666666666668, -20650.555555555555, -20647.222222222223, -20618.333333333332, -6682.222222222223, -6639.444444444444, 1161.6666666666667, -6682.222222222223, -6652.222222222223, -6661.666666666667, -6672.222222222223], time: 338.212
steps: 201435, episodes: 210, mean episode reward: 62911.11111111111, agent episode reward: [-1005.4444444444445, -1005.4444444444445, -1005.4444444444445, -1005.4444444444445, -1007.1111111111111, -1006.0, -1005.4444444444445, 9978.222222222223, 10004.888888888889, 10005.444444444445, 9979.333333333334, 10001.0, 9994.888888888889, 9987.666666666666], time: 1.708
