{'exp_name': 'default', 'display': False, 'restore_fp': None, 'save_rate': 10, 'scenario_name': 'ultimate_frisbee', 'num_episodes': 6000, 'max_episode_len': 10000, 'good_policy': 'matd3', 'adv_policy': 'matd3', 'lr': 0.01, 'gamma': 0.95, 'batch_size': 1024, 'num_layers': 2, 'num_units': 64, 'update_rate': 100, 'critic_zero_if_done': False, 'buff_size': 100000.0, 'tau': 0.01, 'hard_max': False, 'priori_replay': False, 'alpha': 0.6, 'beta': 0.5, 'use_target_action': True, 'policy_update_rate': 1, 'critic_action_noise_stddev': 0.0, 'action_noise_clip': 0.5, 'entropy_coeff': 0.05, 'num_atoms': 51, 'min_val': -400, 'max_val': 0, 'seed': 802200134}
C:\Users\camta\miniconda3\lib\site-packages\keras\optimizers\optimizer_v2\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
Using good policy matd3 and adv policy matd3
61
Starting iterations...
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
steps: 203, episodes: 10, mean episode reward: -786.6666666666666, agent episode reward: [-1020.5555555555555, -1071.6666666666667, -1080.5555555555557, -1072.7777777777778, -1020.5555555555555, -1054.4444444444443, -1052.2222222222222, 917.7777777777778, 942.2222222222222, 917.7777777777778, 960.5555555555555, 998.8888888888889, 917.7777777777778, 931.1111111111111], time: 3.806
steps: 213, episodes: 20, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.747
steps: 223, episodes: 30, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.175
steps: 233, episodes: 40, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.085
steps: 243, episodes: 50, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.125
steps: 253, episodes: 60, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.131
steps: 263, episodes: 70, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.078
steps: 273, episodes: 80, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.148
steps: 283, episodes: 90, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.129
steps: 293, episodes: 100, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.063
steps: 303, episodes: 110, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.076
steps: 313, episodes: 120, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.132
steps: 323, episodes: 130, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.155
steps: 333, episodes: 140, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.042
steps: 343, episodes: 150, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.052
steps: 353, episodes: 160, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.117
steps: 363, episodes: 170, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.134
steps: 373, episodes: 180, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.116
steps: 383, episodes: 190, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.055
steps: 393, episodes: 200, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.024
steps: 403, episodes: 210, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.076
steps: 413, episodes: 220, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.196
steps: 423, episodes: 230, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.081
steps: 433, episodes: 240, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.008
steps: 443, episodes: 250, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.088
steps: 453, episodes: 260, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.055
steps: 463, episodes: 270, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.172
steps: 473, episodes: 280, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.082
steps: 483, episodes: 290, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.107
steps: 493, episodes: 300, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.065
steps: 503, episodes: 310, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.297
steps: 513, episodes: 320, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.27
steps: 523, episodes: 330, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.012
steps: 533, episodes: 340, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.067
steps: 543, episodes: 350, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.063
steps: 553, episodes: 360, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.036
steps: 563, episodes: 370, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.033
steps: 573, episodes: 380, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.079
steps: 583, episodes: 390, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.118
steps: 593, episodes: 400, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.049
steps: 603, episodes: 410, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.195
steps: 613, episodes: 420, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.081
steps: 623, episodes: 430, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.131
steps: 633, episodes: 440, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.139
steps: 643, episodes: 450, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.057
steps: 653, episodes: 460, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.078
steps: 663, episodes: 470, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.071
steps: 673, episodes: 480, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.114
steps: 683, episodes: 490, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.117
steps: 693, episodes: 500, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.068
steps: 703, episodes: 510, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.121
steps: 713, episodes: 520, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.084
steps: 723, episodes: 530, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.139
steps: 733, episodes: 540, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.073
steps: 743, episodes: 550, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.106
steps: 753, episodes: 560, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.064
steps: 763, episodes: 570, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.049
steps: 773, episodes: 580, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.091
steps: 783, episodes: 590, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.109
steps: 793, episodes: 600, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.084
steps: 803, episodes: 610, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.082
steps: 813, episodes: 620, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.11
steps: 823, episodes: 630, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.112
steps: 833, episodes: 640, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.057
steps: 843, episodes: 650, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.059
steps: 853, episodes: 660, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.089
steps: 863, episodes: 670, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.121
steps: 873, episodes: 680, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.123
steps: 883, episodes: 690, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.974
steps: 893, episodes: 700, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.96
steps: 903, episodes: 710, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.035
steps: 913, episodes: 720, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.156
steps: 923, episodes: 730, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.019
steps: 933, episodes: 740, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.088
steps: 943, episodes: 750, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.084
steps: 953, episodes: 760, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.118
steps: 963, episodes: 770, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.303
steps: 973, episodes: 780, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.356
steps: 983, episodes: 790, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.046
steps: 993, episodes: 800, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.072
steps: 1003, episodes: 810, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.079
steps: 1013, episodes: 820, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.042
steps: 1023, episodes: 830, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.082
steps: 1033, episodes: 840, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.102
steps: 1043, episodes: 850, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.019
steps: 1053, episodes: 860, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.052
steps: 1063, episodes: 870, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.181
steps: 1073, episodes: 880, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.046
steps: 1083, episodes: 890, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.047
steps: 1093, episodes: 900, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.087
steps: 1103, episodes: 910, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.066
steps: 1113, episodes: 920, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.06
steps: 1123, episodes: 930, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.101
steps: 1133, episodes: 940, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.109
steps: 1143, episodes: 950, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.053
steps: 1153, episodes: 960, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.114
steps: 1163, episodes: 970, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.08
steps: 1173, episodes: 980, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.004
steps: 1183, episodes: 990, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.97
game has been saved from episode: 1000
steps: 1193, episodes: 1000, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.997
steps: 1203, episodes: 1010, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.051
steps: 1213, episodes: 1020, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.035
steps: 1223, episodes: 1030, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.02
steps: 1233, episodes: 1040, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.077
steps: 1243, episodes: 1050, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.026
steps: 1253, episodes: 1060, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.09
steps: 1263, episodes: 1070, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.101
steps: 1273, episodes: 1080, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.069
steps: 1283, episodes: 1090, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.168
steps: 1293, episodes: 1100, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.141
steps: 1303, episodes: 1110, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.042
steps: 1313, episodes: 1120, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.077
steps: 1323, episodes: 1130, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.091
steps: 1333, episodes: 1140, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.047
steps: 1343, episodes: 1150, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.089
steps: 1353, episodes: 1160, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.002
steps: 1363, episodes: 1170, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.063
steps: 1373, episodes: 1180, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.076
steps: 1383, episodes: 1190, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.13
steps: 1393, episodes: 1200, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.096
steps: 1403, episodes: 1210, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.986
steps: 1413, episodes: 1220, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.981
steps: 1423, episodes: 1230, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.05
steps: 1433, episodes: 1240, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.062
steps: 1443, episodes: 1250, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.096
steps: 1453, episodes: 1260, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.007
steps: 1463, episodes: 1270, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.037
steps: 1473, episodes: 1280, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.039
steps: 1483, episodes: 1290, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.056
steps: 1493, episodes: 1300, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.05
steps: 1503, episodes: 1310, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.129
steps: 1513, episodes: 1320, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.026
steps: 1523, episodes: 1330, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.164
steps: 1533, episodes: 1340, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.165
steps: 1543, episodes: 1350, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.028
steps: 1553, episodes: 1360, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.094
steps: 1563, episodes: 1370, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.163
steps: 1573, episodes: 1380, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.0
steps: 1583, episodes: 1390, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.993
steps: 1593, episodes: 1400, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.022
steps: 1603, episodes: 1410, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.158
steps: 1613, episodes: 1420, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.056
steps: 1623, episodes: 1430, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.143
steps: 1633, episodes: 1440, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.253
steps: 1643, episodes: 1450, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.034
steps: 1653, episodes: 1460, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.05
steps: 1663, episodes: 1470, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.016
steps: 1673, episodes: 1480, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.088
steps: 1683, episodes: 1490, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.027
steps: 1693, episodes: 1500, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.092
steps: 1703, episodes: 1510, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.126
steps: 1713, episodes: 1520, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.053
steps: 1723, episodes: 1530, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.272
steps: 1733, episodes: 1540, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.068
steps: 1743, episodes: 1550, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.102
steps: 1753, episodes: 1560, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.072
steps: 1763, episodes: 1570, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.049
steps: 1773, episodes: 1580, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.047
steps: 1783, episodes: 1590, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.97
steps: 1793, episodes: 1600, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.026
steps: 1803, episodes: 1610, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.013
steps: 1813, episodes: 1620, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.041
steps: 1823, episodes: 1630, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.125
steps: 1833, episodes: 1640, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.058
steps: 1843, episodes: 1650, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.062
steps: 1853, episodes: 1660, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.092
steps: 1863, episodes: 1670, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.087
steps: 1873, episodes: 1680, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.059
steps: 1883, episodes: 1690, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.101
steps: 1893, episodes: 1700, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.1
steps: 1903, episodes: 1710, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.039
steps: 1913, episodes: 1720, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.198
steps: 1923, episodes: 1730, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.09
steps: 1933, episodes: 1740, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.079
steps: 1943, episodes: 1750, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.036
steps: 1953, episodes: 1760, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.07
steps: 1963, episodes: 1770, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.077
steps: 1973, episodes: 1780, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.026
steps: 1983, episodes: 1790, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.048
steps: 1993, episodes: 1800, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.136
steps: 2003, episodes: 1810, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.213
steps: 2013, episodes: 1820, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.068
steps: 2023, episodes: 1830, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.166
steps: 2033, episodes: 1840, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.057
steps: 2043, episodes: 1850, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.103
steps: 2053, episodes: 1860, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.138
steps: 2063, episodes: 1870, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.01
steps: 2073, episodes: 1880, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.04
steps: 2083, episodes: 1890, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.086
steps: 2093, episodes: 1900, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.146
steps: 2103, episodes: 1910, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.168
steps: 2113, episodes: 1920, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.106
steps: 2123, episodes: 1930, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.045
steps: 2133, episodes: 1940, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.052
steps: 2143, episodes: 1950, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.025
steps: 2153, episodes: 1960, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.089
steps: 2163, episodes: 1970, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.067
steps: 2173, episodes: 1980, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.019
steps: 2183, episodes: 1990, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.005
game has been saved from episode: 2000
steps: 2193, episodes: 2000, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.178
steps: 2203, episodes: 2010, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.02
steps: 2213, episodes: 2020, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.023
steps: 2223, episodes: 2030, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.989
steps: 2233, episodes: 2040, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.091
steps: 2243, episodes: 2050, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.121
steps: 2253, episodes: 2060, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.041
steps: 2263, episodes: 2070, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.072
steps: 2273, episodes: 2080, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.073
steps: 2283, episodes: 2090, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.083
steps: 2293, episodes: 2100, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.223
steps: 2303, episodes: 2110, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.069
steps: 2313, episodes: 2120, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.081
steps: 2323, episodes: 2130, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.046
steps: 2333, episodes: 2140, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.085
steps: 2343, episodes: 2150, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.097
steps: 2353, episodes: 2160, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.076
steps: 2363, episodes: 2170, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.076
steps: 2373, episodes: 2180, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.061
steps: 2383, episodes: 2190, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.363
steps: 2393, episodes: 2200, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.016
steps: 2403, episodes: 2210, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.098
steps: 2413, episodes: 2220, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.078
steps: 2423, episodes: 2230, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.992
steps: 2433, episodes: 2240, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.99
steps: 2443, episodes: 2250, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.064
steps: 2453, episodes: 2260, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.028
steps: 2463, episodes: 2270, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.977
steps: 2473, episodes: 2280, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.008
steps: 2483, episodes: 2290, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.17
steps: 2493, episodes: 2300, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.964
steps: 2503, episodes: 2310, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.987
steps: 2513, episodes: 2320, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.005
steps: 2523, episodes: 2330, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.973
steps: 2533, episodes: 2340, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.97
steps: 2543, episodes: 2350, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.989
steps: 2553, episodes: 2360, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.007
steps: 2563, episodes: 2370, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.962
steps: 2573, episodes: 2380, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.985
steps: 2583, episodes: 2390, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.209
steps: 2593, episodes: 2400, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.966
steps: 2603, episodes: 2410, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.973
steps: 2613, episodes: 2420, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.993
steps: 2623, episodes: 2430, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.031
steps: 2633, episodes: 2440, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 999.8888888888889], time: 0.981
steps: 2643, episodes: 2450, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.97
steps: 2653, episodes: 2460, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.013
steps: 2663, episodes: 2470, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.997
steps: 2673, episodes: 2480, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.978
steps: 2683, episodes: 2490, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.176
steps: 2693, episodes: 2500, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.023
steps: 2703, episodes: 2510, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.979
steps: 2713, episodes: 2520, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.981
steps: 2723, episodes: 2530, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.02
steps: 2733, episodes: 2540, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.125
steps: 2743, episodes: 2550, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.015
steps: 2753, episodes: 2560, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.056
steps: 2763, episodes: 2570, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.079
steps: 2773, episodes: 2580, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.012
steps: 2783, episodes: 2590, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.202
steps: 2793, episodes: 2600, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.001
steps: 2803, episodes: 2610, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.964
steps: 2813, episodes: 2620, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.001
steps: 2823, episodes: 2630, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.007
steps: 2833, episodes: 2640, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.134
steps: 2843, episodes: 2650, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.991
steps: 2853, episodes: 2660, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.993
steps: 2863, episodes: 2670, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.009
steps: 2873, episodes: 2680, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.012
steps: 2883, episodes: 2690, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.357
steps: 2893, episodes: 2700, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.161
steps: 2903, episodes: 2710, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.129
steps: 2913, episodes: 2720, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.004
steps: 2923, episodes: 2730, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.054
steps: 2933, episodes: 2740, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.108
steps: 2943, episodes: 2750, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.043
steps: 2953, episodes: 2760, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.999
steps: 2963, episodes: 2770, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.01
steps: 2973, episodes: 2780, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.212
steps: 2983, episodes: 2790, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.093
steps: 2993, episodes: 2800, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.086
steps: 3003, episodes: 2810, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.98
steps: 3013, episodes: 2820, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.995
steps: 3023, episodes: 2830, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.998
steps: 3033, episodes: 2840, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.101
steps: 3043, episodes: 2850, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.041
steps: 3053, episodes: 2860, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.011
steps: 3063, episodes: 2870, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.997
steps: 3073, episodes: 2880, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.233
steps: 3083, episodes: 2890, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.147
steps: 3093, episodes: 2900, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.068
steps: 3103, episodes: 2910, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.984
steps: 3113, episodes: 2920, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.989
steps: 3123, episodes: 2930, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.991
steps: 3133, episodes: 2940, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.106
steps: 3143, episodes: 2950, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.034
steps: 3153, episodes: 2960, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.032
steps: 3163, episodes: 2970, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.048
steps: 3173, episodes: 2980, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.216
steps: 3183, episodes: 2990, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.118
game has been saved from episode: 3000
steps: 3193, episodes: 3000, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 999.8888888888889], time: 1.083
steps: 3203, episodes: 3010, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.988
steps: 3213, episodes: 3020, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.988
steps: 3223, episodes: 3030, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.017
steps: 3233, episodes: 3040, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.192
steps: 3243, episodes: 3050, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.034
steps: 3253, episodes: 3060, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.076
steps: 3263, episodes: 3070, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.323
steps: 3273, episodes: 3080, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.007
steps: 3283, episodes: 3090, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.992
steps: 3293, episodes: 3100, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0], time: 1.017
steps: 3303, episodes: 3110, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.046
steps: 3313, episodes: 3120, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.987
steps: 3323, episodes: 3130, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.0
steps: 3333, episodes: 3140, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.997
steps: 3343, episodes: 3150, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.974
steps: 3353, episodes: 3160, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.966
steps: 3363, episodes: 3170, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.252
steps: 3373, episodes: 3180, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.967
steps: 3383, episodes: 3190, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.972
steps: 3393, episodes: 3200, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.022
steps: 3403, episodes: 3210, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.989
steps: 3413, episodes: 3220, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.006
steps: 3423, episodes: 3230, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.964
steps: 3433, episodes: 3240, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.022
steps: 3443, episodes: 3250, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.021
steps: 3453, episodes: 3260, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.087
steps: 3463, episodes: 3270, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.404
steps: 3473, episodes: 3280, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.045
steps: 3483, episodes: 3290, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.046
steps: 3493, episodes: 3300, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.104
steps: 3503, episodes: 3310, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.054
steps: 3513, episodes: 3320, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.06
steps: 3523, episodes: 3330, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.058
steps: 3533, episodes: 3340, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.035
steps: 3543, episodes: 3350, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.047
steps: 3553, episodes: 3360, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.122
steps: 3563, episodes: 3370, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.455
steps: 3573, episodes: 3380, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.063
steps: 3583, episodes: 3390, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.116
steps: 3593, episodes: 3400, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.015
steps: 3603, episodes: 3410, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.007
steps: 3613, episodes: 3420, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.012
steps: 3623, episodes: 3430, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.998
steps: 3633, episodes: 3440, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.048
steps: 3643, episodes: 3450, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.094
steps: 3653, episodes: 3460, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.344
steps: 3663, episodes: 3470, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.018
steps: 3673, episodes: 3480, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.064
steps: 3683, episodes: 3490, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.08
steps: 3693, episodes: 3500, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.047
steps: 3703, episodes: 3510, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.058
steps: 3713, episodes: 3520, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.083
steps: 3723, episodes: 3530, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.071
steps: 3733, episodes: 3540, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.127
steps: 3743, episodes: 3550, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.072
steps: 3753, episodes: 3560, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.411
steps: 3763, episodes: 3570, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.047
steps: 3773, episodes: 3580, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.118
steps: 3783, episodes: 3590, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.043
steps: 3793, episodes: 3600, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.044
steps: 3803, episodes: 3610, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.031
steps: 3813, episodes: 3620, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.12
steps: 3823, episodes: 3630, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.021
steps: 3833, episodes: 3640, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.009
steps: 3843, episodes: 3650, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.331
steps: 3853, episodes: 3660, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.102
steps: 3863, episodes: 3670, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.043
steps: 3873, episodes: 3680, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.003
steps: 3883, episodes: 3690, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.992
steps: 3893, episodes: 3700, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.974
steps: 3903, episodes: 3710, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.968
steps: 3913, episodes: 3720, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.998
steps: 3923, episodes: 3730, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.988
steps: 3933, episodes: 3740, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.988
steps: 3943, episodes: 3750, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.386
steps: 3953, episodes: 3760, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.067
steps: 3963, episodes: 3770, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.043
steps: 3973, episodes: 3780, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.09
steps: 3983, episodes: 3790, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.097
steps: 3993, episodes: 3800, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.051
steps: 4003, episodes: 3810, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.042
steps: 4013, episodes: 3820, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.099
steps: 4023, episodes: 3830, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.069
steps: 4033, episodes: 3840, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.06
steps: 4043, episodes: 3850, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.341
steps: 4053, episodes: 3860, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.052
steps: 4063, episodes: 3870, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.041
steps: 4073, episodes: 3880, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.101
steps: 4083, episodes: 3890, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.119
steps: 4093, episodes: 3900, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.071
steps: 4103, episodes: 3910, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.114
steps: 4113, episodes: 3920, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.112
steps: 4123, episodes: 3930, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.034
steps: 4133, episodes: 3940, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.338
steps: 4143, episodes: 3950, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.01
steps: 4153, episodes: 3960, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.986
steps: 4163, episodes: 3970, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.003
steps: 4173, episodes: 3980, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.003
steps: 4183, episodes: 3990, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.983
game has been saved from episode: 4000
steps: 4193, episodes: 4000, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.983
steps: 4203, episodes: 4010, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.975
steps: 4213, episodes: 4020, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.003
steps: 4223, episodes: 4030, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.105
steps: 4233, episodes: 4040, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.453
steps: 4243, episodes: 4050, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.087
steps: 4253, episodes: 4060, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.029
steps: 4263, episodes: 4070, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.095
steps: 4273, episodes: 4080, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.09
steps: 4283, episodes: 4090, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.08
steps: 4293, episodes: 4100, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.038
steps: 4303, episodes: 4110, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.127
steps: 4313, episodes: 4120, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.106
steps: 4323, episodes: 4130, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.47
steps: 4333, episodes: 4140, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.079
steps: 4343, episodes: 4150, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 999.8888888888889], time: 1.039
steps: 4353, episodes: 4160, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.037
steps: 4363, episodes: 4170, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.068
steps: 4373, episodes: 4180, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.079
steps: 4383, episodes: 4190, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.038
steps: 4393, episodes: 4200, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.0
steps: 4403, episodes: 4210, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.016
steps: 4413, episodes: 4220, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.036
steps: 4423, episodes: 4230, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.392
steps: 4433, episodes: 4240, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.032
steps: 4443, episodes: 4250, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.06
steps: 4453, episodes: 4260, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.025
steps: 4463, episodes: 4270, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.045
steps: 4473, episodes: 4280, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.051
steps: 4483, episodes: 4290, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.028
steps: 4493, episodes: 4300, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.033
steps: 4503, episodes: 4310, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.08
steps: 4513, episodes: 4320, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.393
steps: 4523, episodes: 4330, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.012
steps: 4533, episodes: 4340, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.012
steps: 4543, episodes: 4350, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.033
steps: 4553, episodes: 4360, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.025
steps: 4563, episodes: 4370, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.067
steps: 4573, episodes: 4380, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.064
steps: 4583, episodes: 4390, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.041
steps: 4593, episodes: 4400, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.014
steps: 4603, episodes: 4410, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.032
steps: 4613, episodes: 4420, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.39
steps: 4623, episodes: 4430, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.994
steps: 4633, episodes: 4440, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.012
steps: 4643, episodes: 4450, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.052
steps: 4653, episodes: 4460, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.022
steps: 4663, episodes: 4470, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.044
steps: 4673, episodes: 4480, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.099
steps: 4683, episodes: 4490, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.022
steps: 4693, episodes: 4500, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.983
steps: 4703, episodes: 4510, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.037
steps: 4713, episodes: 4520, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.429
steps: 4723, episodes: 4530, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.014
steps: 4733, episodes: 4540, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.065
steps: 4743, episodes: 4550, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.048
steps: 4753, episodes: 4560, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 0.999
steps: 4763, episodes: 4570, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.014
steps: 4773, episodes: 4580, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.066
steps: 4783, episodes: 4590, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.026
steps: 4793, episodes: 4600, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.033
steps: 4803, episodes: 4610, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.212
steps: 4813, episodes: 4620, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.455
steps: 4823, episodes: 4630, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.076
steps: 4833, episodes: 4640, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.089
steps: 4843, episodes: 4650, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.99
steps: 4853, episodes: 4660, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.036
steps: 4863, episodes: 4670, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 999.8888888888889], time: 1.05
steps: 4873, episodes: 4680, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.047
steps: 4883, episodes: 4690, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.032
steps: 4893, episodes: 4700, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.054
steps: 4903, episodes: 4710, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.469
steps: 4913, episodes: 4720, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.026
steps: 4923, episodes: 4730, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.018
steps: 4933, episodes: 4740, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.102
steps: 4943, episodes: 4750, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.025
steps: 4953, episodes: 4760, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.024
steps: 4963, episodes: 4770, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.006
steps: 4973, episodes: 4780, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.053
steps: 4983, episodes: 4790, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.029
steps: 4993, episodes: 4800, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.068
steps: 5003, episodes: 4810, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.458
steps: 5013, episodes: 4820, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.034
steps: 5023, episodes: 4830, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.02
steps: 5033, episodes: 4840, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.068
steps: 5043, episodes: 4850, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.027
steps: 5053, episodes: 4860, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.045
steps: 5063, episodes: 4870, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.085
steps: 5073, episodes: 4880, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.04
steps: 5083, episodes: 4890, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.014
steps: 5093, episodes: 4900, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.017
steps: 5103, episodes: 4910, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.48
steps: 5113, episodes: 4920, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.067
steps: 5123, episodes: 4930, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.082
steps: 5133, episodes: 4940, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.095
steps: 5143, episodes: 4950, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 999.3333333333334], time: 1.043
steps: 5153, episodes: 4960, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.045
steps: 5163, episodes: 4970, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.118
steps: 5173, episodes: 4980, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.047
steps: 5183, episodes: 4990, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.025
game has been saved from episode: 5000
steps: 5193, episodes: 5000, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.533
steps: 5203, episodes: 5010, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.049
steps: 5213, episodes: 5020, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.027
steps: 5223, episodes: 5030, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.046
steps: 5233, episodes: 5040, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.048
steps: 5243, episodes: 5050, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.998
steps: 5253, episodes: 5060, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.01
steps: 5263, episodes: 5070, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.099
steps: 5273, episodes: 5080, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.035
steps: 5283, episodes: 5090, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.017
steps: 5293, episodes: 5100, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.443
steps: 5303, episodes: 5110, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.013
steps: 5313, episodes: 5120, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.998
steps: 5323, episodes: 5130, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.061
steps: 5333, episodes: 5140, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.054
steps: 5343, episodes: 5150, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.031
steps: 5353, episodes: 5160, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.063
steps: 5363, episodes: 5170, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.094
steps: 5373, episodes: 5180, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.032
steps: 5383, episodes: 5190, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.415
steps: 5393, episodes: 5200, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.089
steps: 5403, episodes: 5210, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.059
steps: 5413, episodes: 5220, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.049
steps: 5423, episodes: 5230, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.045
steps: 5433, episodes: 5240, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.038
steps: 5443, episodes: 5250, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.024
steps: 5453, episodes: 5260, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.099
steps: 5463, episodes: 5270, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.053
steps: 5473, episodes: 5280, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.033
steps: 5483, episodes: 5290, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.45
steps: 5493, episodes: 5300, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.085
steps: 5503, episodes: 5310, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.035
steps: 5513, episodes: 5320, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.036
steps: 5523, episodes: 5330, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.015
steps: 5533, episodes: 5340, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.039
steps: 5543, episodes: 5350, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.031
steps: 5553, episodes: 5360, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.075
steps: 5563, episodes: 5370, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.044
steps: 5573, episodes: 5380, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.043
steps: 5583, episodes: 5390, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.481
steps: 5593, episodes: 5400, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.04
steps: 5603, episodes: 5410, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.05
steps: 5613, episodes: 5420, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.047
steps: 5623, episodes: 5430, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.066
steps: 5633, episodes: 5440, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.014
steps: 5643, episodes: 5450, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.003
steps: 5653, episodes: 5460, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.134
steps: 5663, episodes: 5470, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.031
steps: 5673, episodes: 5480, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.494
steps: 5683, episodes: 5490, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.082
steps: 5693, episodes: 5500, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.032
steps: 5703, episodes: 5510, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.03
steps: 5713, episodes: 5520, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.114
steps: 5723, episodes: 5530, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.018
steps: 5733, episodes: 5540, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.011
steps: 5743, episodes: 5550, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.054
steps: 5753, episodes: 5560, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.081
steps: 5763, episodes: 5570, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.988
steps: 5773, episodes: 5580, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.527
steps: 5783, episodes: 5590, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.084
steps: 5793, episodes: 5600, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.037
steps: 5803, episodes: 5610, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.996
steps: 5813, episodes: 5620, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.044
steps: 5823, episodes: 5630, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.039
steps: 5833, episodes: 5640, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.031
steps: 5843, episodes: 5650, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.06
steps: 5853, episodes: 5660, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.081
steps: 5863, episodes: 5670, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.033
steps: 5873, episodes: 5680, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.448
steps: 5883, episodes: 5690, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.008
steps: 5893, episodes: 5700, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.983
steps: 5903, episodes: 5710, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.997
steps: 5913, episodes: 5720, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.074
steps: 5923, episodes: 5730, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.03
steps: 5933, episodes: 5740, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.026
steps: 5943, episodes: 5750, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.015
steps: 5953, episodes: 5760, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.057
steps: 5963, episodes: 5770, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.471
steps: 5973, episodes: 5780, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.073
steps: 5983, episodes: 5790, mean episode reward: -15.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1000.4444444444445], time: 1.181
steps: 5993, episodes: 5800, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.132
steps: 6003, episodes: 5810, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 999.8888888888889], time: 1.291
steps: 6013, episodes: 5820, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.107
steps: 6023, episodes: 5830, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.062
steps: 6033, episodes: 5840, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.999
steps: 6043, episodes: 5850, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.06
steps: 6053, episodes: 5860, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.636
steps: 6063, episodes: 5870, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.05
steps: 6073, episodes: 5880, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.041
steps: 6083, episodes: 5890, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.118
steps: 6093, episodes: 5900, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.17
steps: 6103, episodes: 5910, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.102
steps: 6113, episodes: 5920, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.987
steps: 6123, episodes: 5930, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 999.8888888888889], time: 1.031
steps: 6133, episodes: 5940, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.081
steps: 6143, episodes: 5950, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.123
steps: 6153, episodes: 5960, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.482
steps: 6163, episodes: 5970, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.061
steps: 6173, episodes: 5980, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 0.985
steps: 6183, episodes: 5990, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.058
game has been saved from episode: 6000
steps: 6193, episodes: 6000, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 1001.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0], time: 1.106
...Finished total of 6000 episodes in 10.857454041639963 minutes.
61
