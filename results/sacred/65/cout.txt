{'exp_name': 'default', 'display': False, 'restore_fp': None, 'save_rate': 10, 'scenario_name': 'ultimate_frisbee', 'num_episodes': 6000, 'max_episode_len': 10000, 'good_policy': 'matd3', 'adv_policy': 'matd3', 'lr': 0.01, 'gamma': 0.95, 'batch_size': 1024, 'num_layers': 2, 'num_units': 64, 'update_rate': 100, 'critic_zero_if_done': False, 'buff_size': 100000.0, 'tau': 0.01, 'hard_max': False, 'priori_replay': False, 'alpha': 0.6, 'beta': 0.5, 'use_target_action': True, 'policy_update_rate': 1, 'critic_action_noise_stddev': 0.0, 'action_noise_clip': 0.5, 'entropy_coeff': 0.05, 'num_atoms': 51, 'min_val': -400, 'max_val': 0, 'seed': 919234284}
C:\Users\camta\miniconda3\lib\site-packages\keras\optimizers\optimizer_v2\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
Using good policy matd3 and adv policy matd3
65
Starting iterations...
not in bounds
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
not in bounds
not in bounds
not in bounds
not in bounds
not in bounds
not in bounds
not in bounds
not in bounds
steps: 499, episodes: 10, mean episode reward: -1343.888888888889, agent episode reward: [-1172.7777777777778, -1076.111111111111, -1173.3333333333333, -1057.2222222222222, -1068.888888888889, -1078.888888888889, -1091.111111111111, 980.0, 1016.6666666666666, 824.4444444444445, 1024.4444444444443, 824.4444444444445, 860.0, 844.4444444444445], time: 7.47
steps: 509, episodes: 20, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 0.718
steps: 519, episodes: 30, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.023
steps: 529, episodes: 40, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.037
steps: 539, episodes: 50, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.081
steps: 549, episodes: 60, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.046
steps: 559, episodes: 70, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.013
steps: 569, episodes: 80, mean episode reward: -10.555555555555555, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 999.8888888888889, 1001.0], time: 1.014
steps: 579, episodes: 90, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.084
steps: 589, episodes: 100, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.037
steps: 599, episodes: 110, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.04
steps: 609, episodes: 120, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.118
steps: 619, episodes: 130, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.029
steps: 629, episodes: 140, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 0.998
steps: 639, episodes: 150, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.008
steps: 649, episodes: 160, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.076
steps: 659, episodes: 170, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.042
steps: 669, episodes: 180, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.044
steps: 679, episodes: 190, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.095
steps: 689, episodes: 200, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.056
steps: 699, episodes: 210, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.034
steps: 709, episodes: 220, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.074
steps: 719, episodes: 230, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.063
steps: 729, episodes: 240, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.029
steps: 739, episodes: 250, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.029
steps: 749, episodes: 260, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.087
steps: 759, episodes: 270, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.047
steps: 769, episodes: 280, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.004
steps: 779, episodes: 290, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.055
steps: 789, episodes: 300, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.112
steps: 799, episodes: 310, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.022
steps: 809, episodes: 320, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.027
steps: 819, episodes: 330, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.074
steps: 829, episodes: 340, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.044
steps: 839, episodes: 350, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.035
steps: 849, episodes: 360, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.057
steps: 859, episodes: 370, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.053
steps: 869, episodes: 380, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 0.997
steps: 879, episodes: 390, mean episode reward: -11.666666666666666, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.131
steps: 889, episodes: 400, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.031
steps: 899, episodes: 410, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.037
steps: 909, episodes: 420, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.019
steps: 919, episodes: 430, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.065
steps: 929, episodes: 440, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.117
steps: 939, episodes: 450, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.137
steps: 949, episodes: 460, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.064
steps: 959, episodes: 470, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.024
steps: 969, episodes: 480, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.042
steps: 979, episodes: 490, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.146
steps: 989, episodes: 500, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.035
steps: 999, episodes: 510, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.045
steps: 1009, episodes: 520, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.052
steps: 1019, episodes: 530, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.066
steps: 1029, episodes: 540, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.128
steps: 1039, episodes: 550, mean episode reward: -11.666666666666666, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.15
steps: 1049, episodes: 560, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.076
steps: 1059, episodes: 570, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.025
steps: 1069, episodes: 580, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.092
steps: 1079, episodes: 590, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.093
steps: 1089, episodes: 600, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.032
steps: 1099, episodes: 610, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.181
steps: 1109, episodes: 620, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.1
steps: 1119, episodes: 630, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.047
steps: 1129, episodes: 640, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.048
steps: 1139, episodes: 650, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.064
steps: 1149, episodes: 660, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.052
steps: 1159, episodes: 670, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.08
steps: 1169, episodes: 680, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.035
steps: 1179, episodes: 690, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.096
steps: 1189, episodes: 700, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.06
steps: 1199, episodes: 710, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.019
steps: 1209, episodes: 720, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.039
steps: 1219, episodes: 730, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.058
steps: 1229, episodes: 740, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.024
steps: 1239, episodes: 750, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.038
steps: 1249, episodes: 760, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.054
steps: 1259, episodes: 770, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.092
steps: 1269, episodes: 780, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.007
steps: 1279, episodes: 790, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.063
steps: 1289, episodes: 800, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.056
steps: 1299, episodes: 810, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.015
steps: 1309, episodes: 820, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.034
steps: 1319, episodes: 830, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.067
steps: 1329, episodes: 840, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.011
steps: 1339, episodes: 850, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 0.997
steps: 1349, episodes: 860, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 997.1111111111111, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.068
steps: 1359, episodes: 870, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.122
steps: 1369, episodes: 880, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.045
steps: 1379, episodes: 890, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.076
steps: 1389, episodes: 900, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.076
steps: 1399, episodes: 910, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.044
steps: 1409, episodes: 920, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.047
steps: 1419, episodes: 930, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.088
steps: 1429, episodes: 940, mean episode reward: -11.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 999.3333333333334, 1001.0], time: 1.026
steps: 1439, episodes: 950, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.03
steps: 1449, episodes: 960, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.176
steps: 1459, episodes: 970, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.048
steps: 1469, episodes: 980, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.046
steps: 1479, episodes: 990, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.024
game has been saved from episode: 1000
steps: 1489, episodes: 1000, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.5555555555555, 998.2222222222222, 1001.0], time: 1.066
steps: 1499, episodes: 1010, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.047
steps: 1509, episodes: 1020, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.101
steps: 1519, episodes: 1030, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.042
steps: 1529, episodes: 1040, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.044
steps: 1539, episodes: 1050, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.061
steps: 1549, episodes: 1060, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.164
steps: 1559, episodes: 1070, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.022
steps: 1569, episodes: 1080, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.042
steps: 1579, episodes: 1090, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.095
steps: 1589, episodes: 1100, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.0, 1001.0], time: 1.035
steps: 1599, episodes: 1110, mean episode reward: -11.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 997.1111111111111, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.024
steps: 1609, episodes: 1120, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.017
steps: 1619, episodes: 1130, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.003
steps: 1629, episodes: 1140, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.024
steps: 1639, episodes: 1150, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.102
steps: 1649, episodes: 1160, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.05
steps: 1659, episodes: 1170, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.051
steps: 1669, episodes: 1180, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.033
steps: 1679, episodes: 1190, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.07
steps: 1689, episodes: 1200, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.028
steps: 1699, episodes: 1210, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.034
steps: 1709, episodes: 1220, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.06
steps: 1719, episodes: 1230, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.05
steps: 1729, episodes: 1240, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.072
steps: 1739, episodes: 1250, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 997.1111111111111, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.182
steps: 1749, episodes: 1260, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.081
steps: 1759, episodes: 1270, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.0, 1001.0], time: 1.02
steps: 1769, episodes: 1280, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.029
steps: 1779, episodes: 1290, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.101
steps: 1789, episodes: 1300, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.036
steps: 1799, episodes: 1310, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.058
steps: 1809, episodes: 1320, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.06
steps: 1819, episodes: 1330, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.059
steps: 1829, episodes: 1340, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.024
steps: 1839, episodes: 1350, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.147
steps: 1849, episodes: 1360, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.086
steps: 1859, episodes: 1370, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.02
steps: 1869, episodes: 1380, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.043
steps: 1879, episodes: 1390, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.119
steps: 1889, episodes: 1400, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.029
steps: 1899, episodes: 1410, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 0.993
steps: 1909, episodes: 1420, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.5555555555555, 997.1111111111111, 1001.0], time: 1.01
steps: 1919, episodes: 1430, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.06
steps: 1929, episodes: 1440, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.164
steps: 1939, episodes: 1450, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.028
steps: 1949, episodes: 1460, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.136
steps: 1959, episodes: 1470, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.038
steps: 1969, episodes: 1480, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.023
steps: 1979, episodes: 1490, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.085
steps: 1989, episodes: 1500, mean episode reward: -11.666666666666666, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 999.3333333333334, 1001.0], time: 1.046
steps: 1999, episodes: 1510, mean episode reward: -11.666666666666666, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.047
steps: 2009, episodes: 1520, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.029
steps: 2019, episodes: 1530, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.0, 1001.0], time: 1.063
steps: 2029, episodes: 1540, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 996.0, 1001.0], time: 1.17
steps: 2039, episodes: 1550, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 0.99
steps: 2049, episodes: 1560, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.086
steps: 2059, episodes: 1570, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.027
steps: 2069, episodes: 1580, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.047
steps: 2079, episodes: 1590, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.0, 1001.0], time: 1.08
steps: 2089, episodes: 1600, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.058
steps: 2099, episodes: 1610, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.032
steps: 2109, episodes: 1620, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.034
steps: 2119, episodes: 1630, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.208
steps: 2129, episodes: 1640, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.041
steps: 2139, episodes: 1650, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.047
steps: 2149, episodes: 1660, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.1
steps: 2159, episodes: 1670, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.031
steps: 2169, episodes: 1680, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.018
steps: 2179, episodes: 1690, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.024
steps: 2189, episodes: 1700, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.048
steps: 2199, episodes: 1710, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.058
steps: 2209, episodes: 1720, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.7777777777778, 1001.0], time: 1.016
steps: 2219, episodes: 1730, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.196
steps: 2229, episodes: 1740, mean episode reward: -11.666666666666666, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 999.3333333333334, 1001.0], time: 1.047
steps: 2239, episodes: 1750, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.03
steps: 2249, episodes: 1760, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.109
steps: 2259, episodes: 1770, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.062
steps: 2269, episodes: 1780, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.035
steps: 2279, episodes: 1790, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.027
steps: 2289, episodes: 1800, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.064
steps: 2299, episodes: 1810, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.055
steps: 2309, episodes: 1820, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.161
steps: 2319, episodes: 1830, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.061
steps: 2329, episodes: 1840, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.5555555555555, 997.6666666666666, 1001.0], time: 1.075
steps: 2339, episodes: 1850, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.056
steps: 2349, episodes: 1860, mean episode reward: -11.666666666666666, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 999.3333333333334, 1001.0], time: 1.1
steps: 2359, episodes: 1870, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.051
steps: 2369, episodes: 1880, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.051
steps: 2379, episodes: 1890, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.0, 1001.0], time: 1.086
steps: 2389, episodes: 1900, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.09
steps: 2399, episodes: 1910, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.05
steps: 2409, episodes: 1920, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.197
steps: 2419, episodes: 1930, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.0, 1001.0], time: 1.063
steps: 2429, episodes: 1940, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.045
steps: 2439, episodes: 1950, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.123
steps: 2449, episodes: 1960, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.129
steps: 2459, episodes: 1970, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.038
steps: 2469, episodes: 1980, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.031
steps: 2479, episodes: 1990, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.042
game has been saved from episode: 2000
steps: 2489, episodes: 2000, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.015
steps: 2499, episodes: 2010, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.165
steps: 2509, episodes: 2020, mean episode reward: -12.222222222222221, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 997.1111111111111, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.035
steps: 2519, episodes: 2030, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 0.985
steps: 2529, episodes: 2040, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.5555555555555, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.022
steps: 2539, episodes: 2050, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.079
steps: 2549, episodes: 2060, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.0, 1001.0], time: 1.064
steps: 2559, episodes: 2070, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.047
steps: 2569, episodes: 2080, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.019
steps: 2579, episodes: 2090, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 997.1111111111111, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.069
steps: 2589, episodes: 2100, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.037
steps: 2599, episodes: 2110, mean episode reward: -15.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.0, 1001.0], time: 1.198
steps: 2609, episodes: 2120, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.058
steps: 2619, episodes: 2130, mean episode reward: -11.666666666666666, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 999.3333333333334, 1001.0], time: 1.051
steps: 2629, episodes: 2140, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.066
steps: 2639, episodes: 2150, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.113
steps: 2649, episodes: 2160, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.063
steps: 2659, episodes: 2170, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.044
steps: 2669, episodes: 2180, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.09
steps: 2679, episodes: 2190, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.07
steps: 2689, episodes: 2200, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.237
steps: 2699, episodes: 2210, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.138
steps: 2709, episodes: 2220, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.117
steps: 2719, episodes: 2230, mean episode reward: -12.777777777777779, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 998.2222222222222, 1001.0], time: 1.051
steps: 2729, episodes: 2240, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.6666666666666, 1001.0], time: 1.123
steps: 2739, episodes: 2250, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.101
steps: 2749, episodes: 2260, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.077
steps: 2759, episodes: 2270, mean episode reward: -14.444444444444445, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 996.5555555555555, 1001.0], time: 1.071
steps: 2769, episodes: 2280, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.078
steps: 2779, episodes: 2290, mean episode reward: -13.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0, 997.1111111111111, 1001.0], time: 1.048
