{'exp_name': 'default', 'display': False, 'restore_fp': None, 'save_rate': 10, 'scenario_name': 'ultimate_frisbee', 'num_episodes': 6000, 'max_episode_len': 10000, 'good_policy': 'matd3', 'adv_policy': 'matd3', 'lr': 0.01, 'gamma': 0.95, 'batch_size': 1024, 'num_layers': 2, 'num_units': 64, 'update_rate': 100, 'critic_zero_if_done': False, 'buff_size': 100000.0, 'tau': 0.01, 'hard_max': False, 'priori_replay': False, 'alpha': 0.6, 'beta': 0.5, 'use_target_action': True, 'policy_update_rate': 1, 'critic_action_noise_stddev': 0.0, 'action_noise_clip': 0.5, 'entropy_coeff': 0.05, 'num_atoms': 51, 'min_val': -400, 'max_val': 0, 'seed': 993101696}
C:\Users\camta\miniconda3\lib\site-packages\keras\optimizers\optimizer_v2\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
Using good policy matd3 and adv policy matd3
44
Starting iterations...
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
steps: 80007, episodes: 10, mean episode reward: -541301.1111111111, agent episode reward: [-46540.333333333336, -46874.77777777778, -46777.0, -45897.555555555555, -46843.11111111111, -46710.88888888889, -46213.11111111111, -30646.88888888889, -30892.444444444445, -30710.222222222223, -30671.88888888889, -30892.444444444445, -30738.0, -30892.444444444445], time: 867.735
steps: 140016, episodes: 20, mean episode reward: -464047.77777777775, agent episode reward: [-40047.444444444445, -40321.333333333336, -40237.444444444445, -39443.555555555555, -40294.11111111111, -40228.555555555555, -39794.11111111111, -26134.777777777777, -26336.444444444445, -26189.777777777777, -26146.444444444445, -26336.444444444445, -26200.88888888889, -26336.444444444445], time: 666.349
steps: 210025, episodes: 30, mean episode reward: -463811.6666666667, agent episode reward: [-40032.11111111111, -40321.0, -40237.666666666664, -39384.88888888889, -40294.333333333336, -40084.333333333336, -39769.333333333336, -26135.666666666668, -26337.333333333332, -26189.0, -26145.666666666668, -26337.333333333332, -26205.666666666668, -26337.333333333332], time: 795.239
steps: 290030, episodes: 40, mean episode reward: -541422.2222222222, agent episode reward: [-46553.88888888889, -46873.88888888889, -46776.666666666664, -45796.666666666664, -46842.77777777778, -46780.0, -46345.555555555555, -30645.0, -30891.11111111111, -30720.555555555555, -30672.222222222223, -30891.11111111111, -30741.666666666668, -30891.11111111111], time: 902.499
game has been saved from episode: 50
steps: 370038, episodes: 50, mean episode reward: -618443.8888888889, agent episode reward: [-53059.77777777778, -53427.0, -53315.88888888889, -52238.11111111111, -53391.444444444445, -53217.0, -52567.0, -35187.444444444445, -35445.77777777778, -35247.444444444445, -35195.22222222222, -35445.77777777778, -35260.22222222222, -35445.77777777778], time: 895.518
steps: 430047, episodes: 60, mean episode reward: -386455.55555555556, agent episode reward: [-33534.88888888889, -33767.666666666664, -33698.22222222222, -32989.88888888889, -33745.444444444445, -33532.11111111111, -33283.22222222222, -21610.11111111111, -21781.777777777777, -21656.222222222223, -21624.0, -21781.777777777777, -21668.444444444445, -21781.777777777777], time: 682.449
steps: 470061, episodes: 70, mean episode reward: -305173.3333333333, agent episode reward: [-27025.666666666668, -27214.555555555555, -27159.0, -22549.555555555555, -27196.777777777777, -27148.444444444445, -26750.666666666668, -17090.444444444445, -17227.11111111111, -17124.333333333332, -17097.11111111111, -17227.11111111111, -17135.444444444445, -17227.11111111111], time: 453.165
steps: 530074, episodes: 80, mean episode reward: -386438.8888888889, agent episode reward: [-33536.444444444445, -33769.22222222222, -33698.666666666664, -32989.77777777778, -33745.88888888889, -33526.444444444445, -33266.444444444445, -21607.444444444445, -21783.555555555555, -21658.0, -21621.333333333332, -21783.555555555555, -21668.555555555555, -21783.555555555555], time: 679.888
steps: 610081, episodes: 90, mean episode reward: -618378.8888888889, agent episode reward: [-53053.666666666664, -53426.444444444445, -53315.88888888889, -52180.333333333336, -53391.444444444445, -53180.88888888889, -52598.11111111111, -35183.0, -35445.77777777778, -35250.22222222222, -35197.444444444445, -35445.77777777778, -35264.11111111111, -35445.77777777778], time: 910.437
game has been saved from episode: 100
steps: 670090, episodes: 100, mean episode reward: -386547.22222222225, agent episode reward: [-33535.444444444445, -33767.666666666664, -33698.22222222222, -32989.88888888889, -33745.444444444445, -33677.666666666664, -33222.666666666664, -21604.555555555555, -21781.777777777777, -21659.0, -21622.333333333332, -21781.777777777777, -21679.0, -21781.777777777777], time: 677.237
steps: 750092, episodes: 110, mean episode reward: -618383.3333333334, agent episode reward: [-53049.555555555555, -53426.77777777778, -53315.666666666664, -52181.22222222222, -53391.22222222222, -53171.22222222222, -52607.88888888889, -35176.0, -35444.88888888889, -35254.333333333336, -35201.555555555555, -35444.88888888889, -35273.22222222222, -35444.88888888889], time: 904.928
steps: 800104, episodes: 120, mean episode reward: -386723.8888888889, agent episode reward: [-33520.333333333336, -33767.555555555555, -33698.11111111111, -33046.444444444445, -33745.333333333336, -33659.77777777778, -33384.77777777778, -21606.88888888889, -21781.333333333332, -21656.88888888889, -21620.222222222223, -21781.333333333332, -21673.555555555555, -21781.333333333332], time: 566.025
steps: 880106, episodes: 130, mean episode reward: -541309.4444444445, agent episode reward: [-46542.444444444445, -46873.555555555555, -46776.333333333336, -45840.77777777778, -46842.444444444445, -46752.444444444445, -46226.88888888889, -30657.555555555555, -30889.777777777777, -30720.88888888889, -30671.444444444445, -30889.777777777777, -30735.333333333332, -30889.777777777777], time: 864.228
steps: 950111, episodes: 140, mean episode reward: -541335.0, agent episode reward: [-46543.77777777778, -46873.77777777778, -46776.555555555555, -45838.77777777778, -46842.666666666664, -46671.0, -46336.0, -30661.777777777777, -30890.666666666668, -30720.11111111111, -30668.444444444445, -30890.666666666668, -30730.11111111111, -30890.666666666668], time: 758.232
game has been saved from episode: 150
steps: 1020120, episodes: 150, mean episode reward: -463971.1111111111, agent episode reward: [-40047.11111111111, -40321.555555555555, -40237.666666666664, -39499.88888888889, -40294.333333333336, -40241.0, -39657.666666666664, -26130.11111111111, -26337.333333333332, -26185.11111111111, -26144.555555555555, -26337.333333333332, -26200.11111111111, -26337.333333333332], time: 754.072
steps: 1080128, episodes: 160, mean episode reward: -386471.6666666667, agent episode reward: [-33535.88888888889, -33767.555555555555, -33698.11111111111, -32988.666666666664, -33745.333333333336, -33676.444444444445, -33150.88888888889, -21607.444444444445, -21781.333333333332, -21658.0, -21626.88888888889, -21781.333333333332, -21672.444444444445, -21781.333333333332], time: 647.089
steps: 1170129, episodes: 170, mean episode reward: -618548.3333333334, agent episode reward: [-53046.22222222222, -53426.77777777778, -53315.666666666664, -52236.77777777778, -53391.22222222222, -53292.333333333336, -52611.77777777778, -35166.555555555555, -35444.88888888889, -35253.77777777778, -35198.22222222222, -35444.88888888889, -35274.333333333336, -35444.88888888889], time: 986.33
steps: 1250133, episodes: 180, mean episode reward: -541080.5555555555, agent episode reward: [-46541.555555555555, -46873.77777777778, -46776.555555555555, -45784.88888888889, -46842.666666666664, -46595.444444444445, -46217.666666666664, -30667.333333333332, -30890.666666666668, -30717.88888888889, -30669.555555555555, -30890.666666666668, -30721.222222222223, -30890.666666666668], time: 941.747
steps: 1300144, episodes: 190, mean episode reward: -386682.22222222225, agent episode reward: [-33543.11111111111, -33767.555555555555, -33698.11111111111, -32987.555555555555, -33745.333333333336, -33696.444444444445, -33345.88888888889, -21611.88888888889, -21781.333333333332, -21655.777777777777, -21620.222222222223, -21781.333333333332, -21666.333333333332, -21781.333333333332], time: 562.867
