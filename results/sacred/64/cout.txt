{'exp_name': 'default', 'display': False, 'restore_fp': None, 'save_rate': 10, 'scenario_name': 'ultimate_frisbee', 'num_episodes': 6000, 'max_episode_len': 10000, 'good_policy': 'matd3', 'adv_policy': 'matd3', 'lr': 0.01, 'gamma': 0.95, 'batch_size': 1024, 'num_layers': 2, 'num_units': 64, 'update_rate': 100, 'critic_zero_if_done': False, 'buff_size': 100000.0, 'tau': 0.01, 'hard_max': False, 'priori_replay': False, 'alpha': 0.6, 'beta': 0.5, 'use_target_action': True, 'policy_update_rate': 1, 'critic_action_noise_stddev': 0.0, 'action_noise_clip': 0.5, 'entropy_coeff': 0.05, 'num_atoms': 51, 'min_val': -400, 'max_val': 0, 'seed': 7058376}
C:\Users\camta\miniconda3\lib\site-packages\keras\optimizers\optimizer_v2\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
Using good policy matd3 and adv policy matd3
64
Starting iterations...
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
steps: 206, episodes: 10, mean episode reward: -817.2222222222222, agent episode reward: [-1067.4444444444443, -1018.0, -1078.0, -1083.5555555555557, -1089.6666666666667, -1083.5555555555557, -1031.888888888889, 928.5555555555555, 929.1111111111111, 955.2222222222222, 1004.1111111111111, 928.0, 961.8888888888889, 928.0], time: 4.086
steps: 216, episodes: 20, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 0.717
steps: 226, episodes: 30, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.151
steps: 236, episodes: 40, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.074
steps: 246, episodes: 50, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 999.3333333333334, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.108
steps: 256, episodes: 60, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.156
steps: 266, episodes: 70, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.053
steps: 276, episodes: 80, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.231
steps: 286, episodes: 90, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.122
steps: 296, episodes: 100, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.062
steps: 306, episodes: 110, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.114
steps: 316, episodes: 120, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.044
steps: 326, episodes: 130, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.102
steps: 336, episodes: 140, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.091
steps: 346, episodes: 150, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.073
steps: 356, episodes: 160, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.093
steps: 366, episodes: 170, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.072
steps: 376, episodes: 180, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.139
steps: 386, episodes: 190, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.067
steps: 396, episodes: 200, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.182
steps: 406, episodes: 210, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.059
steps: 416, episodes: 220, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.238
steps: 426, episodes: 230, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.141
steps: 436, episodes: 240, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.107
steps: 446, episodes: 250, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.059
steps: 456, episodes: 260, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.162
steps: 466, episodes: 270, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.081
steps: 476, episodes: 280, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.102
steps: 486, episodes: 290, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.045
steps: 496, episodes: 300, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.085
steps: 506, episodes: 310, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.114
steps: 516, episodes: 320, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.066
steps: 526, episodes: 330, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.061
steps: 536, episodes: 340, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.105
steps: 546, episodes: 350, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.065
steps: 556, episodes: 360, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.049
steps: 566, episodes: 370, mean episode reward: -20.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.122
steps: 576, episodes: 380, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.07
steps: 586, episodes: 390, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.09
steps: 596, episodes: 400, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.127
steps: 606, episodes: 410, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.148
steps: 616, episodes: 420, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.128
steps: 626, episodes: 430, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.072
steps: 636, episodes: 440, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.112
steps: 646, episodes: 450, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.058
steps: 656, episodes: 460, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.06
steps: 666, episodes: 470, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.161
steps: 676, episodes: 480, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.044
steps: 686, episodes: 490, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.157
steps: 696, episodes: 500, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.172
steps: 706, episodes: 510, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.043
steps: 716, episodes: 520, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.104
steps: 726, episodes: 530, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.143
steps: 736, episodes: 540, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.05
steps: 746, episodes: 550, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.035
steps: 756, episodes: 560, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.087
steps: 766, episodes: 570, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.06
steps: 776, episodes: 580, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.041
steps: 786, episodes: 590, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.085
steps: 796, episodes: 600, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.06
steps: 806, episodes: 610, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.072
steps: 816, episodes: 620, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.063
steps: 826, episodes: 630, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.087
steps: 836, episodes: 640, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.065
steps: 846, episodes: 650, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.077
steps: 856, episodes: 660, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.1
steps: 866, episodes: 670, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.188
steps: 876, episodes: 680, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.22
steps: 886, episodes: 690, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.144
steps: 896, episodes: 700, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.151
steps: 906, episodes: 710, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 999.3333333333334, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.144
steps: 916, episodes: 720, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.103
steps: 926, episodes: 730, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.172
steps: 936, episodes: 740, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.063
steps: 946, episodes: 750, mean episode reward: -13.333333333333334, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 998.7777777777778, 999.8888888888889, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.096
steps: 956, episodes: 760, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.143
steps: 966, episodes: 770, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.086
steps: 976, episodes: 780, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.092
steps: 986, episodes: 790, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.139
steps: 996, episodes: 800, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.035
steps: 1006, episodes: 810, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.062
steps: 1016, episodes: 820, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.059
steps: 1026, episodes: 830, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.114
steps: 1036, episodes: 840, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.046
steps: 1046, episodes: 850, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.073
steps: 1056, episodes: 860, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.184
steps: 1066, episodes: 870, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.146
steps: 1076, episodes: 880, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.096
steps: 1086, episodes: 890, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.114
steps: 1096, episodes: 900, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.058
steps: 1106, episodes: 910, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.102
steps: 1116, episodes: 920, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.122
steps: 1126, episodes: 930, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.095
steps: 1136, episodes: 940, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.187
steps: 1146, episodes: 950, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.264
steps: 1156, episodes: 960, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.048
steps: 1166, episodes: 970, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.024
steps: 1176, episodes: 980, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.053
steps: 1186, episodes: 990, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.096
game has been saved from episode: 1000
steps: 1196, episodes: 1000, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.051
steps: 1206, episodes: 1010, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.049
steps: 1216, episodes: 1020, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.095
steps: 1226, episodes: 1030, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.07
steps: 1236, episodes: 1040, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.175
steps: 1246, episodes: 1050, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.117
steps: 1256, episodes: 1060, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.09
steps: 1266, episodes: 1070, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.073
steps: 1276, episodes: 1080, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.153
steps: 1286, episodes: 1090, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.145
steps: 1296, episodes: 1100, mean episode reward: -20.0, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.042
steps: 1306, episodes: 1110, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.041
steps: 1316, episodes: 1120, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.098
steps: 1326, episodes: 1130, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.069
steps: 1336, episodes: 1140, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.18
steps: 1346, episodes: 1150, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 999.3333333333334, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.075
steps: 1356, episodes: 1160, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.04
steps: 1366, episodes: 1170, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.096
steps: 1376, episodes: 1180, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.07
steps: 1386, episodes: 1190, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.036
steps: 1396, episodes: 1200, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.027
steps: 1406, episodes: 1210, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.061
steps: 1416, episodes: 1220, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.042
steps: 1426, episodes: 1230, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.166
steps: 1436, episodes: 1240, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.09
steps: 1446, episodes: 1250, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.033
steps: 1456, episodes: 1260, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.05
steps: 1466, episodes: 1270, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.049
steps: 1476, episodes: 1280, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.072
steps: 1486, episodes: 1290, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.044
steps: 1496, episodes: 1300, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.041
steps: 1506, episodes: 1310, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.092
steps: 1516, episodes: 1320, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.194
steps: 1526, episodes: 1330, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.045
steps: 1536, episodes: 1340, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.075
steps: 1546, episodes: 1350, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.052
steps: 1556, episodes: 1360, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.024
steps: 1566, episodes: 1370, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.042
steps: 1576, episodes: 1380, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.082
steps: 1586, episodes: 1390, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.022
steps: 1596, episodes: 1400, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.015
steps: 1606, episodes: 1410, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.072
steps: 1616, episodes: 1420, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.233
steps: 1626, episodes: 1430, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.119
steps: 1636, episodes: 1440, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.179
steps: 1646, episodes: 1450, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.058
steps: 1656, episodes: 1460, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.054
steps: 1666, episodes: 1470, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.096
steps: 1676, episodes: 1480, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.046
steps: 1686, episodes: 1490, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.04
steps: 1696, episodes: 1500, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.088
steps: 1706, episodes: 1510, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.196
steps: 1716, episodes: 1520, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.024
steps: 1726, episodes: 1530, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.009
steps: 1736, episodes: 1540, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.073
steps: 1746, episodes: 1550, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.045
steps: 1756, episodes: 1560, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.044
steps: 1766, episodes: 1570, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.054
steps: 1776, episodes: 1580, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.081
steps: 1786, episodes: 1590, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.038
steps: 1796, episodes: 1600, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.06
steps: 1806, episodes: 1610, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.222
steps: 1816, episodes: 1620, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.137
steps: 1826, episodes: 1630, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.066
steps: 1836, episodes: 1640, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.077
steps: 1846, episodes: 1650, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.043
steps: 1856, episodes: 1660, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.032
steps: 1866, episodes: 1670, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.048
steps: 1876, episodes: 1680, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.048
steps: 1886, episodes: 1690, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.05
steps: 1896, episodes: 1700, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.243
steps: 1906, episodes: 1710, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.056
steps: 1916, episodes: 1720, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.043
steps: 1926, episodes: 1730, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.078
steps: 1936, episodes: 1740, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.068
steps: 1946, episodes: 1750, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.051
steps: 1956, episodes: 1760, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.029
steps: 1966, episodes: 1770, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.091
steps: 1976, episodes: 1780, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.045
steps: 1986, episodes: 1790, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.023
steps: 1996, episodes: 1800, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.25
steps: 2006, episodes: 1810, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.088
steps: 2016, episodes: 1820, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.141
steps: 2026, episodes: 1830, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.113
steps: 2036, episodes: 1840, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.068
steps: 2046, episodes: 1850, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.056
steps: 2056, episodes: 1860, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.109
steps: 2066, episodes: 1870, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.104
steps: 2076, episodes: 1880, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.13
steps: 2086, episodes: 1890, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.264
steps: 2096, episodes: 1900, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.123
steps: 2106, episodes: 1910, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.095
steps: 2116, episodes: 1920, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.108
steps: 2126, episodes: 1930, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.141
steps: 2136, episodes: 1940, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.065
steps: 2146, episodes: 1950, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.066
steps: 2156, episodes: 1960, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.062
steps: 2166, episodes: 1970, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.061
steps: 2176, episodes: 1980, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.258
steps: 2186, episodes: 1990, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.118
game has been saved from episode: 2000
steps: 2196, episodes: 2000, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.066
steps: 2206, episodes: 2010, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.044
steps: 2216, episodes: 2020, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.106
steps: 2226, episodes: 2030, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.093
steps: 2236, episodes: 2040, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.074
steps: 2246, episodes: 2050, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.174
steps: 2256, episodes: 2060, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.297
steps: 2266, episodes: 2070, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.366
steps: 2276, episodes: 2080, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.079
steps: 2286, episodes: 2090, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.08
steps: 2296, episodes: 2100, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.118
steps: 2306, episodes: 2110, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.159
steps: 2316, episodes: 2120, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.206
steps: 2326, episodes: 2130, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.106
steps: 2336, episodes: 2140, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.156
steps: 2346, episodes: 2150, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.199
steps: 2356, episodes: 2160, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.318
steps: 2366, episodes: 2170, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.048
steps: 2376, episodes: 2180, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.073
steps: 2386, episodes: 2190, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.047
steps: 2396, episodes: 2200, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.046
steps: 2406, episodes: 2210, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.066
steps: 2416, episodes: 2220, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.039
steps: 2426, episodes: 2230, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.024
steps: 2436, episodes: 2240, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.034
steps: 2446, episodes: 2250, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.215
steps: 2456, episodes: 2260, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.015
steps: 2466, episodes: 2270, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.075
steps: 2476, episodes: 2280, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.037
steps: 2486, episodes: 2290, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.018
steps: 2496, episodes: 2300, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.024
steps: 2506, episodes: 2310, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.046
steps: 2516, episodes: 2320, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.035
steps: 2526, episodes: 2330, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.024
steps: 2536, episodes: 2340, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.062
steps: 2546, episodes: 2350, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.247
steps: 2556, episodes: 2360, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.014
steps: 2566, episodes: 2370, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.053
steps: 2576, episodes: 2380, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.071
steps: 2586, episodes: 2390, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.068
steps: 2596, episodes: 2400, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.074
steps: 2606, episodes: 2410, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.079
steps: 2616, episodes: 2420, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.053
steps: 2626, episodes: 2430, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.037
steps: 2636, episodes: 2440, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.106
steps: 2646, episodes: 2450, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.24
steps: 2656, episodes: 2460, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.014
steps: 2666, episodes: 2470, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.192
steps: 2676, episodes: 2480, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.101
steps: 2686, episodes: 2490, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.048
steps: 2696, episodes: 2500, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.068
steps: 2706, episodes: 2510, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.074
steps: 2716, episodes: 2520, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.041
steps: 2726, episodes: 2530, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.038
steps: 2736, episodes: 2540, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.331
steps: 2746, episodes: 2550, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.14
steps: 2756, episodes: 2560, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.134
steps: 2766, episodes: 2570, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.26
steps: 2776, episodes: 2580, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.181
steps: 2786, episodes: 2590, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.0, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.195
steps: 2796, episodes: 2600, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.096
steps: 2806, episodes: 2610, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.079
steps: 2816, episodes: 2620, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.127
steps: 2826, episodes: 2630, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.291
steps: 2836, episodes: 2640, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.028
steps: 2846, episodes: 2650, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.04
steps: 2856, episodes: 2660, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.153
steps: 2866, episodes: 2670, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.114
steps: 2876, episodes: 2680, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.014
steps: 2886, episodes: 2690, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.06
steps: 2896, episodes: 2700, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.042
steps: 2906, episodes: 2710, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.116
steps: 2916, episodes: 2720, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.316
steps: 2926, episodes: 2730, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.021
steps: 2936, episodes: 2740, mean episode reward: -16.11111111111111, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.062
steps: 2946, episodes: 2750, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.198
steps: 2956, episodes: 2760, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.147
steps: 2966, episodes: 2770, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.6666666666666, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.057
steps: 2976, episodes: 2780, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.18
steps: 2986, episodes: 2790, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.257
steps: 2996, episodes: 2800, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.112
steps: 3006, episodes: 2810, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 998.2222222222222, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.321
steps: 3016, episodes: 2820, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.045
steps: 3026, episodes: 2830, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.142
steps: 3036, episodes: 2840, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.234
steps: 3046, episodes: 2850, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.154
steps: 3056, episodes: 2860, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.031
steps: 3066, episodes: 2870, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.117
steps: 3076, episodes: 2880, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.25
steps: 3086, episodes: 2890, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.7777777777778, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.069
steps: 3096, episodes: 2900, mean episode reward: -17.77777777777778, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.292
steps: 3106, episodes: 2910, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.059
steps: 3116, episodes: 2920, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.6666666666666, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.087
steps: 3126, episodes: 2930, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.135
steps: 3136, episodes: 2940, mean episode reward: -18.333333333333332, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.054
steps: 3146, episodes: 2950, mean episode reward: -17.22222222222222, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.5555555555555, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.026
steps: 3156, episodes: 2960, mean episode reward: -16.666666666666668, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 997.1111111111111, 998.2222222222222, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.047
steps: 3166, episodes: 2970, mean episode reward: -18.88888888888889, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 997.1111111111111, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.132
steps: 3176, episodes: 2980, mean episode reward: -19.444444444444443, agent episode reward: [-1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, -1001.0, 996.0, 996.5555555555555, 1001.0, 1001.0, 996.0, 1001.0, 996.0], time: 1.12
