{'exp_name': 'default', 'display': False, 'restore_fp': 'results/sacred/77/models', 'save_rate': 10, 'scenario_name': 'ultimate_frisbee', 'num_episodes': 50000, 'max_episode_len': 10000, 'good_policy': 'matd3', 'adv_policy': 'matd3', 'lr': 0.01, 'gamma': 0.95, 'batch_size': 1024, 'num_layers': 2, 'num_units': 64, 'update_rate': 100, 'critic_zero_if_done': False, 'buff_size': 100000.0, 'tau': 0.01, 'hard_max': False, 'priori_replay': False, 'alpha': 0.6, 'beta': 0.5, 'use_target_action': True, 'policy_update_rate': 1, 'critic_action_noise_stddev': 0.0, 'action_noise_clip': 0.5, 'entropy_coeff': 0.05, 'num_atoms': 51, 'min_val': -400, 'max_val': 0, 'seed': 278291070}
C:\Users\camta\miniconda3\lib\site-packages\keras\optimizers\optimizer_v2\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(Adam, self).__init__(name, **kwargs)
Using good policy matd3 and adv policy matd3
78
Loading previous state...
Starting iterations...
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\camta\miniconda3\lib\site-packages\numpy\core\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
steps: 86, episodes: 10, mean episode reward: -60.0, agent episode reward: [-990.5555555555555, -990.5555555555555, -990.5555555555555, -990.5555555555555, -990.5555555555555, -990.5555555555555, -990.5555555555555, 962.2222222222222, 1006.1111111111111, 1009.4444444444445, 962.2222222222222, 962.2222222222222, 1009.4444444444445, 962.2222222222222], time: 3.949
steps: 215, episodes: 20, mean episode reward: -94.11111111111111, agent episode reward: [-988.1111111111111, -988.1111111111111, -988.1111111111111, -994.7777777777778, -988.1111111111111, -991.4444444444445, -993.1111111111111, 952.4444444444445, 1004.1111111111111, 1011.8888888888889, 952.4444444444445, 952.4444444444445, 1011.8888888888889, 952.4444444444445], time: 2.273
steps: 342, episodes: 30, mean episode reward: -80.0, agent episode reward: [-987.7777777777778, -987.7777777777778, -987.7777777777778, -989.4444444444445, -987.7777777777778, -987.7777777777778, -987.7777777777778, 951.1111111111111, 1007.2222222222222, 1012.2222222222222, 951.1111111111111, 951.1111111111111, 1012.2222222222222, 951.1111111111111], time: 2.699
steps: 489, episodes: 40, mean episode reward: -98.77777777777777, agent episode reward: [-986.2222222222222, -986.2222222222222, -986.2222222222222, -993.4444444444445, -986.2222222222222, -990.1111111111111, -991.2222222222222, 944.8888888888889, 1013.7777777777778, 1013.7777777777778, 944.8888888888889, 944.8888888888889, 1013.7777777777778, 944.8888888888889], time: 2.726
steps: 633, episodes: 50, mean episode reward: -104.66666666666667, agent episode reward: [-985.3333333333334, -985.3333333333334, -985.3333333333334, -992.5555555555555, -985.3333333333334, -988.1111111111111, -992.0, 941.3333333333334, 1014.6666666666666, 1014.6666666666666, 941.3333333333334, 941.3333333333334, 1014.6666666666666, 941.3333333333334], time: 2.733
steps: 722, episodes: 60, mean episode reward: -51.77777777777778, agent episode reward: [-992.6666666666666, -992.6666666666666, -992.6666666666666, -995.4444444444445, -992.6666666666666, -994.3333333333334, -994.3333333333334, 970.6666666666666, 1005.6666666666666, 1007.3333333333334, 970.6666666666666, 970.6666666666666, 1007.3333333333334, 970.6666666666666], time: 1.883
steps: 870, episodes: 70, mean episode reward: -117.33333333333333, agent episode reward: [-983.7777777777778, -983.7777777777778, -983.7777777777778, -992.6666666666666, -983.7777777777778, -987.6666666666666, -986.5555555555555, 935.1111111111111, 1011.7777777777778, 1016.2222222222222, 935.1111111111111, 935.1111111111111, 1016.2222222222222, 935.1111111111111], time: 2.562
steps: 949, episodes: 80, mean episode reward: -65.22222222222223, agent episode reward: [-991.4444444444445, -991.4444444444445, -991.4444444444445, -995.8888888888889, -991.4444444444445, -992.5555555555555, -993.1111111111111, 965.7777777777778, 1001.8888888888889, 1008.5555555555555, 965.7777777777778, 965.7777777777778, 1008.5555555555555, 965.7777777777778], time: 1.97
steps: 1017, episodes: 90, mean episode reward: -44.0, agent episode reward: [-992.6666666666666, -992.6666666666666, -992.6666666666666, -992.6666666666666, -992.6666666666666, -992.6666666666666, -992.6666666666666, 970.6666666666666, 1007.3333333333334, 1007.3333333333334, 970.6666666666666, 970.6666666666666, 1007.3333333333334, 970.6666666666666], time: 1.612
steps: 1133, episodes: 100, mean episode reward: -80.88888888888889, agent episode reward: [-988.5555555555555, -988.5555555555555, -988.5555555555555, -994.1111111111111, -988.5555555555555, -991.8888888888889, -991.8888888888889, 954.2222222222222, 1011.4444444444445, 1011.4444444444445, 954.2222222222222, 954.2222222222222, 1011.4444444444445, 954.2222222222222], time: 2.426
steps: 1223, episodes: 110, mean episode reward: -80.88888888888889, agent episode reward: [-990.2222222222222, -990.2222222222222, -990.2222222222222, -996.8888888888889, -990.2222222222222, -993.0, -995.2222222222222, 960.8888888888889, 1002.0, 1009.7777777777778, 960.8888888888889, 960.8888888888889, 1009.7777777777778, 960.8888888888889], time: 1.944
steps: 1334, episodes: 120, mean episode reward: -81.55555555555556, agent episode reward: [-987.8888888888889, -987.8888888888889, -987.8888888888889, -990.6666666666666, -987.8888888888889, -989.5555555555555, -990.1111111111111, 951.5555555555555, 1009.8888888888889, 1012.1111111111111, 951.5555555555555, 951.5555555555555, 1012.1111111111111, 951.5555555555555], time: 2.013
steps: 1455, episodes: 130, mean episode reward: -83.0, agent episode reward: [-988.1111111111111, -988.1111111111111, -988.1111111111111, -994.2222222222222, -988.1111111111111, -991.4444444444445, -990.3333333333334, 952.4444444444445, 1011.8888888888889, 1011.8888888888889, 952.4444444444445, 952.4444444444445, 1011.8888888888889, 952.4444444444445], time: 2.461
steps: 1572, episodes: 140, mean episode reward: -90.55555555555556, agent episode reward: [-987.2222222222222, -987.2222222222222, -987.2222222222222, -993.3333333333334, -987.2222222222222, -991.6666666666666, -990.5555555555555, 948.8888888888889, 1012.7777777777778, 1012.7777777777778, 948.8888888888889, 948.8888888888889, 1012.7777777777778, 948.8888888888889], time: 2.204
steps: 1680, episodes: 150, mean episode reward: -74.44444444444444, agent episode reward: [-990.0, -990.0, -990.0, -994.4444444444445, -990.0, -991.6666666666666, -992.7777777777778, 960.0, 1004.4444444444445, 1010.0, 960.0, 960.0, 1010.0, 960.0], time: 2.303
steps: 1804, episodes: 160, mean episode reward: -96.11111111111111, agent episode reward: [-988.3333333333334, -988.3333333333334, -988.3333333333334, -993.8888888888889, -988.3333333333334, -992.2222222222222, -992.7777777777778, 953.3333333333334, 999.4444444444445, 1011.6666666666666, 953.3333333333334, 953.3333333333334, 1011.6666666666666, 953.3333333333334], time: 2.279
steps: 1904, episodes: 170, mean episode reward: -71.44444444444444, agent episode reward: [-989.1111111111111, -989.1111111111111, -989.1111111111111, -991.3333333333334, -989.1111111111111, -989.6666666666666, -989.1111111111111, 956.4444444444445, 1007.5555555555555, 1010.8888888888889, 956.4444444444445, 956.4444444444445, 1010.8888888888889, 956.4444444444445], time: 2.16
steps: 1979, episodes: 180, mean episode reward: -43.22222222222222, agent episode reward: [-994.0, -994.0, -994.0, -995.1111111111111, -994.0, -994.5555555555555, -994.0, 976.0, 1000.4444444444445, 1006.0, 976.0, 976.0, 1006.0, 976.0], time: 1.784
steps: 2122, episodes: 190, mean episode reward: -99.66666666666667, agent episode reward: [-986.4444444444445, -986.4444444444445, -986.4444444444445, -992.0, -986.4444444444445, -988.1111111111111, -989.7777777777778, 945.7777777777778, 1005.7777777777778, 1013.5555555555555, 945.7777777777778, 945.7777777777778, 1013.5555555555555, 945.7777777777778], time: 2.438
steps: 2275, episodes: 200, mean episode reward: -122.33333333333333, agent episode reward: [-983.2222222222222, -983.2222222222222, -983.2222222222222, -990.4444444444445, -983.2222222222222, -984.8888888888889, -984.8888888888889, 932.8888888888889, 1005.6666666666666, 1016.7777777777778, 932.8888888888889, 932.8888888888889, 1016.7777777777778, 932.8888888888889], time: 2.803
steps: 2390, episodes: 210, mean episode reward: -78.11111111111111, agent episode reward: [-987.4444444444445, -987.4444444444445, -987.4444444444445, -989.6666666666666, -987.4444444444445, -988.0, -987.4444444444445, 949.7777777777778, 1012.5555555555555, 1012.5555555555555, 949.7777777777778, 949.7777777777778, 1012.5555555555555, 949.7777777777778], time: 2.185
steps: 2509, episodes: 220, mean episode reward: -74.44444444444444, agent episode reward: [-988.8888888888889, -988.8888888888889, -988.8888888888889, -992.2222222222222, -988.8888888888889, -988.8888888888889, -989.4444444444445, 955.5555555555555, 1007.2222222222222, 1011.1111111111111, 955.5555555555555, 955.5555555555555, 1011.1111111111111, 955.5555555555555], time: 2.498
steps: 2640, episodes: 230, mean episode reward: -92.0, agent episode reward: [-986.8888888888889, -986.8888888888889, -986.8888888888889, -993.5555555555555, -986.8888888888889, -989.1111111111111, -991.3333333333334, 947.5555555555555, 1013.1111111111111, 1013.1111111111111, 947.5555555555555, 947.5555555555555, 1013.1111111111111, 947.5555555555555], time: 2.66
steps: 2740, episodes: 240, mean episode reward: -55.44444444444444, agent episode reward: [-991.2222222222222, -991.2222222222222, -991.2222222222222, -992.8888888888889, -991.2222222222222, -992.3333333333334, -991.2222222222222, 964.8888888888889, 1008.7777777777778, 1008.7777777777778, 964.8888888888889, 964.8888888888889, 1008.7777777777778, 964.8888888888889], time: 2.259
steps: 2852, episodes: 250, mean episode reward: -72.0, agent episode reward: [-989.1111111111111, -989.1111111111111, -989.1111111111111, -992.4444444444445, -989.1111111111111, -991.8888888888889, -989.6666666666666, 956.4444444444445, 1010.8888888888889, 1010.8888888888889, 956.4444444444445, 956.4444444444445, 1010.8888888888889, 956.4444444444445], time: 2.078
steps: 2920, episodes: 260, mean episode reward: -46.77777777777778, agent episode reward: [-992.6666666666666, -992.6666666666666, -992.6666666666666, -994.3333333333334, -992.6666666666666, -993.2222222222222, -993.2222222222222, 970.6666666666666, 1007.3333333333334, 1007.3333333333334, 970.6666666666666, 970.6666666666666, 1007.3333333333334, 970.6666666666666], time: 1.646
steps: 2987, episodes: 270, mean episode reward: -30.666666666666668, agent episode reward: [-994.8888888888889, -994.8888888888889, -994.8888888888889, -994.8888888888889, -994.8888888888889, -994.8888888888889, -994.8888888888889, 979.5555555555555, 1005.1111111111111, 1005.1111111111111, 979.5555555555555, 979.5555555555555, 1005.1111111111111, 979.5555555555555], time: 1.679
steps: 3125, episodes: 280, mean episode reward: -98.77777777777777, agent episode reward: [-987.3333333333334, -987.3333333333334, -987.3333333333334, -994.0, -987.3333333333334, -991.2222222222222, -990.6666666666666, 949.3333333333334, 1003.7777777777778, 1012.6666666666666, 949.3333333333334, 949.3333333333334, 1012.6666666666666, 949.3333333333334], time: 2.605
steps: 3202, episodes: 290, mean episode reward: -79.44444444444444, agent episode reward: [-991.6666666666666, -991.6666666666666, -991.6666666666666, -997.7777777777778, -991.6666666666666, -994.4444444444445, -997.7777777777778, 966.6666666666666, 993.8888888888889, 1008.3333333333334, 966.6666666666666, 966.6666666666666, 1008.3333333333334, 966.6666666666666], time: 2.158
steps: 3281, episodes: 300, mean episode reward: -60.22222222222222, agent episode reward: [-991.4444444444445, -991.4444444444445, -991.4444444444445, -994.2222222222222, -991.4444444444445, -992.0, -992.5555555555555, 965.7777777777778, 1004.1111111111111, 1008.5555555555555, 965.7777777777778, 965.7777777777778, 1008.5555555555555, 965.7777777777778], time: 1.92
steps: 3392, episodes: 310, mean episode reward: -66.88888888888889, agent episode reward: [-989.7777777777778, -989.7777777777778, -989.7777777777778, -990.3333333333334, -989.7777777777778, -989.7777777777778, -989.7777777777778, 959.1111111111111, 1005.2222222222222, 1010.2222222222222, 959.1111111111111, 959.1111111111111, 1010.2222222222222, 959.1111111111111], time: 2.35
steps: 3506, episodes: 320, mean episode reward: -77.33333333333333, agent episode reward: [-988.7777777777778, -988.7777777777778, -988.7777777777778, -992.6666666666666, -988.7777777777778, -991.5555555555555, -992.1111111111111, 955.1111111111111, 1011.2222222222222, 1011.2222222222222, 955.1111111111111, 955.1111111111111, 1011.2222222222222, 955.1111111111111], time: 2.326
steps: 3625, episodes: 330, mean episode reward: -73.66666666666667, agent episode reward: [-989.1111111111111, -989.1111111111111, -989.1111111111111, -993.0, -989.1111111111111, -991.3333333333334, -991.3333333333334, 956.4444444444445, 1010.8888888888889, 1010.8888888888889, 956.4444444444445, 956.4444444444445, 1010.8888888888889, 956.4444444444445], time: 2.18
steps: 3747, episodes: 340, mean episode reward: -88.88888888888889, agent episode reward: [-986.6666666666666, -986.6666666666666, -986.6666666666666, -991.6666666666666, -986.6666666666666, -990.0, -987.2222222222222, 946.6666666666666, 1013.3333333333334, 1013.3333333333334, 946.6666666666666, 946.6666666666666, 1013.3333333333334, 946.6666666666666], time: 2.599
steps: 3910, episodes: 350, mean episode reward: -117.44444444444444, agent episode reward: [-983.6666666666666, -983.6666666666666, -983.6666666666666, -993.6666666666666, -983.6666666666666, -988.1111111111111, -984.7777777777778, 934.6666666666666, 1012.4444444444445, 1016.3333333333334, 934.6666666666666, 934.6666666666666, 1016.3333333333334, 934.6666666666666], time: 2.692
steps: 4032, episodes: 360, mean episode reward: -75.77777777777777, agent episode reward: [-988.1111111111111, -988.1111111111111, -988.1111111111111, -990.8888888888889, -988.1111111111111, -989.2222222222222, -988.6666666666666, 952.4444444444445, 1011.8888888888889, 1011.8888888888889, 952.4444444444445, 952.4444444444445, 1011.8888888888889, 952.4444444444445], time: 2.56
steps: 4092, episodes: 370, mean episode reward: -54.22222222222222, agent episode reward: [-993.5555555555555, -993.5555555555555, -993.5555555555555, -998.0, -993.5555555555555, -994.1111111111111, -997.4444444444445, 974.2222222222222, 999.7777777777778, 1006.4444444444445, 974.2222222222222, 974.2222222222222, 1006.4444444444445, 974.2222222222222], time: 1.529
steps: 4210, episodes: 380, mean episode reward: -94.55555555555556, agent episode reward: [-987.1111111111111, -987.1111111111111, -987.1111111111111, -992.1111111111111, -987.1111111111111, -987.6666666666666, -989.8888888888889, 948.4444444444445, 1004.0, 1012.8888888888889, 948.4444444444445, 948.4444444444445, 1012.8888888888889, 948.4444444444445], time: 2.357
steps: 4330, episodes: 390, mean episode reward: -72.88888888888889, agent episode reward: [-988.7777777777778, -988.7777777777778, -988.7777777777778, -992.1111111111111, -988.7777777777778, -988.7777777777778, -991.0, 955.1111111111111, 1011.2222222222222, 1011.2222222222222, 955.1111111111111, 955.1111111111111, 1011.2222222222222, 955.1111111111111], time: 2.27
steps: 4458, episodes: 400, mean episode reward: -84.66666666666667, agent episode reward: [-987.5555555555555, -987.5555555555555, -987.5555555555555, -991.4444444444445, -987.5555555555555, -990.8888888888889, -989.2222222222222, 950.2222222222222, 1011.3333333333334, 1012.4444444444445, 950.2222222222222, 950.2222222222222, 1012.4444444444445, 950.2222222222222], time: 2.34
steps: 4609, episodes: 410, mean episode reward: -110.0, agent episode reward: [-984.4444444444445, -984.4444444444445, -984.4444444444445, -992.7777777777778, -984.4444444444445, -988.8888888888889, -988.3333333333334, 937.7777777777778, 1015.5555555555555, 1015.5555555555555, 937.7777777777778, 937.7777777777778, 1015.5555555555555, 937.7777777777778], time: 3.157
steps: 4745, episodes: 420, mean episode reward: -104.44444444444444, agent episode reward: [-986.6666666666666, -986.6666666666666, -986.6666666666666, -993.8888888888889, -986.6666666666666, -990.5555555555555, -991.6666666666666, 946.6666666666666, 1005.0, 1013.3333333333334, 946.6666666666666, 946.6666666666666, 1013.3333333333334, 946.6666666666666], time: 2.515
steps: 4887, episodes: 430, mean episode reward: -103.55555555555556, agent episode reward: [-986.4444444444445, -986.4444444444445, -986.4444444444445, -997.0, -986.4444444444445, -991.4444444444445, -992.5555555555555, 945.7777777777778, 1013.0, 1013.5555555555555, 945.7777777777778, 945.7777777777778, 1013.5555555555555, 945.7777777777778], time: 2.565
steps: 5038, episodes: 440, mean episode reward: -125.44444444444444, agent episode reward: [-983.4444444444445, -983.4444444444445, -983.4444444444445, -995.6666666666666, -983.4444444444445, -988.4444444444445, -987.3333333333334, 933.7777777777778, 1011.5555555555555, 1016.5555555555555, 933.7777777777778, 933.7777777777778, 1016.5555555555555, 933.7777777777778], time: 2.551
steps: 5150, episodes: 450, mean episode reward: -70.22222222222223, agent episode reward: [-989.7777777777778, -989.7777777777778, -989.7777777777778, -992.0, -989.7777777777778, -990.3333333333334, -990.8888888888889, 959.1111111111111, 1005.2222222222222, 1010.2222222222222, 959.1111111111111, 959.1111111111111, 1010.2222222222222, 959.1111111111111], time: 2.297
steps: 5292, episodes: 460, mean episode reward: -97.44444444444444, agent episode reward: [-985.8888888888889, -985.8888888888889, -985.8888888888889, -993.1111111111111, -985.8888888888889, -987.5555555555555, -989.7777777777778, 943.5555555555555, 1014.1111111111111, 1014.1111111111111, 943.5555555555555, 943.5555555555555, 1014.1111111111111, 943.5555555555555], time: 2.478
steps: 5440, episodes: 470, mean episode reward: -103.22222222222223, agent episode reward: [-985.1111111111111, -985.1111111111111, -985.1111111111111, -992.8888888888889, -985.1111111111111, -989.0, -987.3333333333334, 940.4444444444445, 1014.8888888888889, 1014.8888888888889, 940.4444444444445, 940.4444444444445, 1014.8888888888889, 940.4444444444445], time: 2.83
steps: 5513, episodes: 480, mean episode reward: -50.666666666666664, agent episode reward: [-992.1111111111111, -992.1111111111111, -992.1111111111111, -993.7777777777778, -992.1111111111111, -992.6666666666666, -993.2222222222222, 968.4444444444445, 1007.8888888888889, 1007.8888888888889, 968.4444444444445, 968.4444444444445, 1007.8888888888889, 968.4444444444445], time: 1.681
steps: 5577, episodes: 490, mean episode reward: -30.666666666666668, agent episode reward: [-994.8888888888889, -994.8888888888889, -994.8888888888889, -994.8888888888889, -994.8888888888889, -994.8888888888889, -994.8888888888889, 979.5555555555555, 1005.1111111111111, 1005.1111111111111, 979.5555555555555, 979.5555555555555, 1005.1111111111111, 979.5555555555555], time: 1.733
steps: 5693, episodes: 500, mean episode reward: -95.22222222222223, agent episode reward: [-988.6666666666666, -988.6666666666666, -988.6666666666666, -994.2222222222222, -988.6666666666666, -993.6666666666666, -992.0, 954.6666666666666, 998.0, 1011.3333333333334, 954.6666666666666, 954.6666666666666, 1011.3333333333334, 954.6666666666666], time: 2.238
steps: 5806, episodes: 510, mean episode reward: -68.44444444444444, agent episode reward: [-989.8888888888889, -989.8888888888889, -989.8888888888889, -993.2222222222222, -989.8888888888889, -990.4444444444445, -992.6666666666666, 959.5555555555555, 1009.0, 1010.1111111111111, 959.5555555555555, 959.5555555555555, 1010.1111111111111, 959.5555555555555], time: 2.198
steps: 5933, episodes: 520, mean episode reward: -79.66666666666667, agent episode reward: [-988.1111111111111, -988.1111111111111, -988.1111111111111, -990.3333333333334, -988.1111111111111, -989.2222222222222, -988.1111111111111, 952.4444444444445, 1006.8888888888889, 1011.8888888888889, 952.4444444444445, 952.4444444444445, 1011.8888888888889, 952.4444444444445], time: 2.591
steps: 6089, episodes: 530, mean episode reward: -138.22222222222223, agent episode reward: [-982.8888888888889, -982.8888888888889, -982.8888888888889, -993.4444444444445, -982.8888888888889, -990.1111111111111, -989.0, 931.5555555555555, 1005.4444444444445, 1017.1111111111111, 931.5555555555555, 931.5555555555555, 1017.1111111111111, 931.5555555555555], time: 2.685
steps: 6180, episodes: 540, mean episode reward: -77.77777777777777, agent episode reward: [-991.1111111111111, -991.1111111111111, -991.1111111111111, -998.8888888888889, -991.6666666666666, -994.4444444444445, -997.2222222222222, 964.4444444444445, 1002.2222222222222, 1008.8888888888889, 964.4444444444445, 964.4444444444445, 1008.8888888888889, 964.4444444444445], time: 2.177
steps: 6300, episodes: 550, mean episode reward: -88.11111111111111, agent episode reward: [-986.8888888888889, -986.8888888888889, -986.8888888888889, -991.8888888888889, -986.8888888888889, -989.6666666666666, -988.5555555555555, 947.5555555555555, 1013.1111111111111, 1013.1111111111111, 947.5555555555555, 947.5555555555555, 1013.1111111111111, 947.5555555555555], time: 2.296
steps: 6373, episodes: 560, mean episode reward: -47.0, agent episode reward: [-993.5555555555555, -993.5555555555555, -993.5555555555555, -998.0, -993.5555555555555, -995.2222222222222, -995.7777777777778, 974.2222222222222, 1006.4444444444445, 1006.4444444444445, 974.2222222222222, 974.2222222222222, 1006.4444444444445, 974.2222222222222], time: 1.922
steps: 6464, episodes: 570, mean episode reward: -81.55555555555556, agent episode reward: [-990.1111111111111, -990.1111111111111, -990.1111111111111, -995.1111111111111, -990.1111111111111, -992.8888888888889, -994.0, 960.4444444444445, 999.3333333333334, 1009.8888888888889, 960.4444444444445, 960.4444444444445, 1009.8888888888889, 960.4444444444445], time: 1.927
steps: 6538, episodes: 580, mean episode reward: -59.111111111111114, agent episode reward: [-992.0, -992.0, -992.0, -994.7777777777778, -992.0, -992.5555555555555, -993.6666666666666, 968.0, 1001.8888888888889, 1008.0, 968.0, 968.0, 1008.0, 968.0], time: 1.703
steps: 6629, episodes: 590, mean episode reward: -68.22222222222223, agent episode reward: [-990.1111111111111, -990.1111111111111, -990.1111111111111, -994.5555555555555, -990.1111111111111, -991.2222222222222, -993.4444444444445, 960.4444444444445, 1009.8888888888889, 1009.8888888888889, 960.4444444444445, 960.4444444444445, 1009.8888888888889, 960.4444444444445], time: 2.175
steps: 6744, episodes: 600, mean episode reward: -93.11111111111111, agent episode reward: [-988.5555555555555, -988.5555555555555, -988.5555555555555, -995.2222222222222, -988.5555555555555, -993.0, -994.1111111111111, 954.2222222222222, 1003.6666666666666, 1011.4444444444445, 954.2222222222222, 954.2222222222222, 1011.4444444444445, 954.2222222222222], time: 2.255
steps: 6859, episodes: 610, mean episode reward: -75.11111111111111, agent episode reward: [-989.3333333333334, -989.3333333333334, -989.3333333333334, -994.8888888888889, -989.3333333333334, -991.5555555555555, -992.6666666666666, 957.3333333333334, 1010.6666666666666, 1010.6666666666666, 957.3333333333334, 957.3333333333334, 1010.6666666666666, 957.3333333333334], time: 2.363
steps: 6986, episodes: 620, mean episode reward: -87.44444444444444, agent episode reward: [-988.1111111111111, -988.1111111111111, -988.1111111111111, -993.1111111111111, -988.1111111111111, -990.3333333333334, -992.0, 952.4444444444445, 1006.8888888888889, 1011.8888888888889, 952.4444444444445, 952.4444444444445, 1011.8888888888889, 952.4444444444445], time: 2.378
steps: 7094, episodes: 630, mean episode reward: -94.0, agent episode reward: [-988.2222222222222, -988.2222222222222, -988.2222222222222, -995.4444444444445, -989.8888888888889, -992.1111111111111, -992.1111111111111, 952.8888888888889, 1005.1111111111111, 1011.7777777777778, 952.8888888888889, 952.8888888888889, 1011.7777777777778, 952.8888888888889], time: 2.394
steps: 7257, episodes: 640, mean episode reward: -122.66666666666667, agent episode reward: [-984.0, -984.0, -984.0, -994.0, -984.0, -986.7777777777778, -990.1111111111111, 936.0, 1008.2222222222222, 1016.0, 936.0, 936.0, 1016.0, 936.0], time: 3.926
steps: 7379, episodes: 650, mean episode reward: -93.33333333333333, agent episode reward: [-986.6666666666666, -986.6666666666666, -986.6666666666666, -993.8888888888889, -986.6666666666666, -991.1111111111111, -988.3333333333334, 946.6666666666666, 1013.3333333333334, 1013.3333333333334, 946.6666666666666, 946.6666666666666, 1013.3333333333334, 946.6666666666666], time: 2.657
steps: 7488, episodes: 660, mean episode reward: -79.55555555555556, agent episode reward: [-989.8888888888889, -989.8888888888889, -989.8888888888889, -993.7777777777778, -989.8888888888889, -992.1111111111111, -991.5555555555555, 959.5555555555555, 999.0, 1010.1111111111111, 959.5555555555555, 959.5555555555555, 1010.1111111111111, 959.5555555555555], time: 2.34
steps: 7605, episodes: 670, mean episode reward: -80.22222222222223, agent episode reward: [-988.1111111111111, -988.1111111111111, -988.1111111111111, -991.4444444444445, -988.1111111111111, -989.7777777777778, -990.3333333333334, 952.4444444444445, 1010.2222222222222, 1011.8888888888889, 952.4444444444445, 952.4444444444445, 1011.8888888888889, 952.4444444444445], time: 2.286
steps: 7760, episodes: 680, mean episode reward: -118.44444444444444, agent episode reward: [-984.8888888888889, -984.8888888888889, -984.8888888888889, -997.1111111111111, -984.8888888888889, -988.7777777777778, -993.2222222222222, 939.5555555555555, 1011.7777777777778, 1015.1111111111111, 939.5555555555555, 939.5555555555555, 1015.1111111111111, 939.5555555555555], time: 3.172
steps: 7856, episodes: 690, mean episode reward: -74.88888888888889, agent episode reward: [-989.5555555555555, -989.5555555555555, -989.5555555555555, -996.2222222222222, -989.5555555555555, -992.3333333333334, -992.3333333333334, 958.2222222222222, 1010.4444444444445, 1010.4444444444445, 958.2222222222222, 958.2222222222222, 1010.4444444444445, 958.2222222222222], time: 2.125
steps: 7967, episodes: 700, mean episode reward: -83.77777777777777, agent episode reward: [-987.8888888888889, -987.8888888888889, -987.8888888888889, -994.5555555555555, -987.8888888888889, -989.5555555555555, -990.6666666666666, 951.5555555555555, 1012.1111111111111, 1012.1111111111111, 951.5555555555555, 951.5555555555555, 1012.1111111111111, 951.5555555555555], time: 2.697
steps: 8075, episodes: 710, mean episode reward: -79.44444444444444, agent episode reward: [-990.0, -990.0, -990.0, -995.5555555555555, -990.0, -993.3333333333334, -992.7777777777778, 960.0, 1002.2222222222222, 1010.0, 960.0, 960.0, 1010.0, 960.0], time: 2.653
steps: 8230, episodes: 720, mean episode reward: -110.88888888888889, agent episode reward: [-983.0, -983.0, -983.0, -989.6666666666666, -983.0, -984.6666666666666, -983.5555555555555, 932.0, 1017.0, 1017.0, 932.0, 932.0, 1017.0, 932.0], time: 3.26
steps: 8347, episodes: 730, mean episode reward: -90.22222222222223, agent episode reward: [-988.6666666666666, -988.6666666666666, -988.6666666666666, -993.6666666666666, -988.6666666666666, -989.7777777777778, -990.8888888888889, 954.6666666666666, 997.4444444444445, 1011.3333333333334, 954.6666666666666, 954.6666666666666, 1011.3333333333334, 954.6666666666666], time: 2.642
steps: 8417, episodes: 740, mean episode reward: -49.77777777777778, agent episode reward: [-992.4444444444445, -992.4444444444445, -992.4444444444445, -995.2222222222222, -992.4444444444445, -993.0, -993.5555555555555, 969.7777777777778, 1007.5555555555555, 1007.5555555555555, 969.7777777777778, 969.7777777777778, 1007.5555555555555, 969.7777777777778], time: 2.018
steps: 8526, episodes: 750, mean episode reward: -82.44444444444444, agent episode reward: [-988.1111111111111, -988.1111111111111, -988.1111111111111, -990.8888888888889, -988.1111111111111, -988.1111111111111, -989.7777777777778, 952.4444444444445, 1005.2222222222222, 1011.8888888888889, 952.4444444444445, 952.4444444444445, 1011.8888888888889, 952.4444444444445], time: 2.571
steps: 8645, episodes: 760, mean episode reward: -81.88888888888889, agent episode reward: [-989.2222222222222, -989.2222222222222, -989.2222222222222, -993.1111111111111, -989.2222222222222, -990.8888888888889, -992.5555555555555, 956.8888888888889, 1002.4444444444445, 1010.7777777777778, 956.8888888888889, 956.8888888888889, 1010.7777777777778, 956.8888888888889], time: 2.746
steps: 8768, episodes: 770, mean episode reward: -91.22222222222223, agent episode reward: [-986.5555555555555, -986.5555555555555, -986.5555555555555, -988.7777777777778, -986.5555555555555, -987.1111111111111, -986.5555555555555, 946.2222222222222, 1005.6666666666666, 1013.4444444444445, 946.2222222222222, 946.2222222222222, 1013.4444444444445, 946.2222222222222], time: 2.809
steps: 8871, episodes: 780, mean episode reward: -97.88888888888889, agent episode reward: [-988.7777777777778, -988.7777777777778, -988.7777777777778, -998.7777777777778, -988.7777777777778, -993.7777777777778, -997.1111111111111, 955.1111111111111, 1004.0, 1011.2222222222222, 955.1111111111111, 955.1111111111111, 1011.2222222222222, 955.1111111111111], time: 2.498
steps: 9009, episodes: 790, mean episode reward: -93.77777777777777, agent episode reward: [-986.7777777777778, -986.7777777777778, -986.7777777777778, -994.0, -986.7777777777778, -991.2222222222222, -989.5555555555555, 947.1111111111111, 1013.2222222222222, 1013.2222222222222, 947.1111111111111, 947.1111111111111, 1013.2222222222222, 947.1111111111111], time: 3.046
steps: 9104, episodes: 800, mean episode reward: -82.55555555555556, agent episode reward: [-989.6666666666666, -989.6666666666666, -989.6666666666666, -994.6666666666666, -989.6666666666666, -991.8888888888889, -993.5555555555555, 958.6666666666666, 1000.8888888888889, 1010.3333333333334, 958.6666666666666, 958.6666666666666, 1010.3333333333334, 958.6666666666666], time: 2.308
steps: 9234, episodes: 810, mean episode reward: -92.55555555555556, agent episode reward: [-988.0, -988.0, -988.0, -994.1111111111111, -988.0, -990.7777777777778, -993.0, 952.0, 1005.3333333333334, 1012.0, 952.0, 952.0, 1012.0, 952.0], time: 3.004
steps: 9369, episodes: 820, mean episode reward: -98.33333333333333, agent episode reward: [-987.2222222222222, -987.2222222222222, -987.2222222222222, -993.8888888888889, -987.2222222222222, -987.7777777777778, -991.1111111111111, 948.8888888888889, 1002.2222222222222, 1012.7777777777778, 948.8888888888889, 948.8888888888889, 1012.7777777777778, 948.8888888888889], time: 3.135
